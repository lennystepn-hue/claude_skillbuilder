{
  "id": "project-retrospective",
  "name": "project-retrospective",
  "description": "Facilitate effective sprint retrospectives, capture action items, and synthesize team feedback for continuous improvement",
  "category": "Project",
  "content": "---\nname: project-retrospective\ndescription: Facilitate effective sprint retrospectives, capture action items, and synthesize team feedback for continuous improvement\ncategory: Project\n---\n\n# Sprint Retrospectives & Team Feedback\n\n## Overview\n\nThis skill helps facilitate productive retrospectives using proven formats like Start-Stop-Continue, Sailboat, 4Ls, and Mad-Sad-Glad. It generates structured retrospective documents, captures actionable insights, tracks improvement metrics, and helps teams build a culture of continuous improvement. Perfect for agile teams, project post-mortems, and quarterly team reviews.\n\n## Activation\n\nThis skill activates when users request:\n- Sprint retrospectives or retro facilitation\n- Post-mortem analysis or incident reviews\n- Team feedback sessions or health checks\n- Action item tracking from retrospectives\n- Continuous improvement documentation\n- Agile ceremony facilitation\n- Project closure reviews\n\n## Instructions\n\n### Planning a Retrospective\n\n1. **Choose the Right Format**\n   - **Start-Stop-Continue**: Simple, effective for regular sprints\n   - **Sailboat/Speedboat**: Visual metaphor for goals and obstacles\n   - **4Ls (Liked, Learned, Lacked, Longed For)**: Comprehensive reflection\n   - **Mad-Sad-Glad**: Emotion-focused feedback\n   - **Timeline/Events**: For complex projects or incidents\n   - **KALM (Keep, Add, Less, More)**: Alternative to Start-Stop-Continue\n\n2. **Set Up the Session**\n   - Schedule 60-90 minutes for sprint retros\n   - 2-3 hours for project post-mortems\n   - Ensure psychological safety\n   - Use anonymous input tools if needed\n   - Prepare data: metrics, incidents, achievements\n\n3. **Facilitate Effectively**\n   - Set the stage (5-10 minutes)\n   - Gather data (15-20 minutes)\n   - Generate insights (20-30 minutes)\n   - Decide actions (15-20 minutes)\n   - Close the retro (5-10 minutes)\n\n4. **Capture Action Items**\n   - Make them specific and measurable\n   - Assign owners and due dates\n   - Limit to 2-5 high-impact actions\n   - Track completion in next retro\n\n5. **Track Improvements**\n   - Monitor recurring themes\n   - Measure action item completion rate\n   - Track team satisfaction metrics\n   - Celebrate wins and progress\n\n### Creating Retrospective Documents\n\n1. **Pre-Retro Preparation**\n   - Gather sprint metrics (velocity, completion rate)\n   - Note significant events or incidents\n   - Review previous action items\n   - Prepare discussion prompts\n\n2. **During Retro**\n   - Capture all feedback verbatim\n   - Group similar items into themes\n   - Vote on priority topics\n   - Define concrete action items\n\n3. **Post-Retro Documentation**\n   - Summarize key insights\n   - Document action items with owners\n   - Share with stakeholders\n   - Archive for future reference\n\n## Examples\n\n### Example 1: Standard Sprint Retrospective (Start-Stop-Continue)\n\n**User Request**: \"Create a retrospective summary for our 2-week sprint. The team mentioned issues with PR review times, but we successfully launched the new dashboard.\"\n\n**Assistant Response**:\n\n```markdown\n# Sprint 47 Retrospective - January 8-19, 2024\n## Team: Platform Engineering\n\n### Sprint Overview\n- **Duration**: 2 weeks (Jan 8-19)\n- **Completed**: 23/28 story points (82%)\n- **Velocity**: 23 points (target: 25)\n- **Team Sentiment**: 7.2/10 (up from 6.8)\n\n### Major Achievements\n- Successfully launched Customer Analytics Dashboard\n- Zero production incidents\n- Reduced technical debt by 15%\n\n### Key Metrics\n- **Cycle Time**: 4.2 days (up from 3.8)\n- **PR Review Time**: 18 hours avg (up from 12)\n- **Deployment Frequency**: 12 deploys (target: 10)\n- **Bug Escape Rate**: 2% (target: <5%)\n\n---\n\n## Start-Stop-Continue Framework\n\n### START (New practices to adopt)\n\n#### 1. Dedicated PR Review Time Blocks\n- **Feedback**: \"PRs are sitting for days. I end up context-switching constantly.\"\n- **Theme**: Code review bottlenecks (5 mentions)\n- **Proposed Action**: Daily 10am-11am PR review hour\n- **Expected Impact**: Reduce review time from 18h to <8h\n- **Owner**: Sarah (Engineering Manager)\n- **Target**: Implement starting Sprint 48\n\n#### 2. Mid-Sprint Check-ins\n- **Feedback**: \"We realized on day 8 that tickets were blocked.\"\n- **Theme**: Communication gaps (3 mentions)\n- **Proposed Action**: 15-min Wednesday sync to surface blockers\n- **Expected Impact**: Earlier blocker identification\n- **Owner**: Marcus (Scrum Master)\n- **Target**: Start next sprint\n\n#### 3. Celebrate Wins in Standup\n- **Feedback**: \"We shipped a huge feature but barely acknowledged it.\"\n- **Theme**: Team morale (4 mentions)\n- **Proposed Action**: Share one win at each standup\n- **Expected Impact**: Improve team sentiment\n- **Owner**: Everyone (rotation)\n- **Target**: Immediate\n\n### STOP (Practices to eliminate)\n\n#### 1. Meetings Without Clear Agendas\n- **Feedback**: \"30 minutes wasted because we didn't know the goal.\"\n- **Theme**: Meeting efficiency (6 mentions)\n- **Proposed Action**: No meeting without agenda shared 24h prior\n- **Expected Impact**: Save 2-3 hours per person per sprint\n- **Owner**: All meeting organizers\n- **Enforcement**: Marcus to decline agenda-less meetings\n\n#### 2. Scope Creep Mid-Sprint\n- **Feedback**: \"We added 3 'urgent' tickets that derailed our plans.\"\n- **Theme**: Sprint commitment (4 mentions)\n- **Proposed Action**: Strict policy - no mid-sprint additions unless P0\n- **Expected Impact**: Better predictability, less context switching\n- **Owner**: Product Manager + Sarah\n- **Exception Process**: Documented in team charter\n\n#### 3. Working in Isolation\n- **Feedback**: \"I struggled for a day before realizing Alex solved this.\"\n- **Theme**: Knowledge sharing (3 mentions)\n- **Proposed Action**: Pair programming for complex tasks\n- **Expected Impact**: Faster problem solving, knowledge transfer\n- **Owner**: Engineering leads to schedule pairing\n\n### CONTINUE (Effective practices to maintain)\n\n#### 1. Comprehensive Documentation\n- **Feedback**: \"The dashboard docs made onboarding new contributors easy.\"\n- **Theme**: Documentation quality (7 mentions)\n- **Current Practice**: ADRs, README updates, inline comments\n- **Why It Works**: Reduces ramp-up time, fewer questions\n- **Keep Doing**: Maintain documentation as acceptance criteria\n\n#### 2. Automated Testing\n- **Feedback**: \"CI caught 5 bugs before production.\"\n- **Theme**: Quality assurance (5 mentions)\n- **Current Practice**: 87% test coverage, automated regression\n- **Why It Works**: Confidence in deployments, faster releases\n- **Keep Doing**: Maintain >85% coverage requirement\n\n#### 3. Async Standups\n- **Feedback**: \"Written standups save 30 min daily and are more thoughtful.\"\n- **Theme**: Remote work efficiency (8 mentions)\n- **Current Practice**: Slack standup bot, sync 2x/week\n- **Why It Works**: Timezone flexibility, written record\n- **Keep Doing**: Current hybrid model\n\n---\n\n## Action Items Summary\n\n### High Priority (Sprint 48)\n\n| Action | Owner | Due Date | Success Metric | Status |\n|--------|-------|----------|----------------|--------|\n| Implement daily PR review hour (10-11am) | Sarah | Jan 22 | Avg review time <8h | Not Started |\n| Create mid-sprint check-in meeting | Marcus | Jan 22 | 100% attendance | Not Started |\n| Document agenda policy | Marcus | Jan 26 | Zero agenda-less meetings | Not Started |\n| Establish scope freeze policy | PM + Sarah | Jan 23 | <1 mid-sprint addition | Not Started |\n\n### Medium Priority (Sprint 49)\n\n| Action | Owner | Due Date | Success Metric | Status |\n|--------|-------|----------|----------------|--------|\n| Set up pairing rotation | Tech Leads | Feb 5 | 2 pairing sessions/week | Not Started |\n| Create celebration ritual | Team | Ongoing | Sentiment score >7.5 | In Progress |\n\n---\n\n## Retrospective on Retrospectives\n\n### What Worked This Retro\n- Anonymous submission (via Miro) increased candor\n- Dot voting helped prioritize discussion topics\n- Time-boxing kept us focused\n\n### What to Improve Next Time\n- Start with previous action item review (we forgot)\n- Invite Product Manager for better context\n- Use timer to stick to schedule\n\n---\n\n## Themes & Patterns\n\n### Recurring from Previous Sprints\n- **PR review times**: 3rd sprint in a row (ESCALATING)\n- **Meeting efficiency**: 2nd mention (requires attention)\n\n### New Issues\n- **Scope creep**: First time mentioned as major issue\n- **Knowledge silos**: Emerging concern\n\n### Positive Trends\n- **Documentation**: 4 sprints of consistent praise\n- **Team morale**: Improving (6.5 ‚Üí 6.8 ‚Üí 7.2)\n- **Deployment confidence**: Testing investment paying off\n\n---\n\n## Metrics to Watch Next Sprint\n\n1. **PR Review Time**: Target <8h average (current: 18h)\n2. **Mid-Sprint Additions**: Target <1 (current: 3)\n3. **Team Sentiment**: Target >7.5 (current: 7.2)\n4. **Action Item Completion**: Target 100% (will track)\n\n---\n\n## Appendix: Raw Feedback\n\n### What Went Well\n- \"Dashboard launch was smooth, great teamwork\" - 6 üëç\n- \"Zero prod issues this sprint\" - 5 üëç\n- \"Documentation has been excellent\" - 7 üëç\n- \"Async standups are so much better than meetings\" - 8 üëç\n- \"CI/CD pipeline is rock solid\" - 5 üëç\n\n### What Didn't Go Well\n- \"PRs sitting for days is frustrating\" - 5 üëç\n- \"Too many unplanned 'urgent' requests\" - 4 üëç\n- \"Meetings without agendas waste time\" - 6 üëç\n- \"Felt isolated working on complex ticket\" - 3 üëç\n- \"Realized blockers too late in sprint\" - 3 üëç\n\n### Ideas for Improvement\n- \"Dedicated PR review time each day\" - 7 üëç\n- \"Strict scope freeze policy\" - 4 üëç\n- \"Pair programming for hard problems\" - 3 üëç\n- \"Mid-sprint sync to surface issues\" - 3 üëç\n- \"Celebrate wins more often\" - 4 üëç\n```\n\n---\n\n### Example 2: Project Post-Mortem (Incident Analysis)\n\n**User Request**: \"We had a 3-hour outage last week. Create a post-mortem retrospective to understand what happened and prevent it from happening again.\"\n\n**Assistant Response**:\n\n```markdown\n# Post-Mortem: API Outage - January 15, 2024\n## Incident #2024-001\n\n### Executive Summary\n\nOn January 15, 2024, our API experienced a complete outage from 14:23 to 17:45 UTC (3h 22min), affecting 100% of customers. The root cause was a database connection pool exhaustion triggered by a memory leak in the new caching layer deployed earlier that day. Total customer impact: 2,847 customers, estimated $45K revenue impact.\n\n**This should not have happened. This document explains why it did and how we'll prevent it.**\n\n---\n\n## Incident Timeline\n\n### Pre-Incident\n- **09:00**: Deployed v2.4.0 with new Redis caching layer\n- **09:15**: Post-deployment health checks passed\n- **14:00**: Monitoring showed gradual memory increase (dismissed as cache warming)\n\n### Incident\n- **14:23**: First alerts - API response time >5s\n- **14:25**: Support tickets flooding in\n- **14:28**: Incident declared, war room formed\n- **14:35**: Identified all database connections exhausted\n- **14:50**: Attempted connection pool increase (failed - memory issue)\n- **15:20**: Root cause identified - memory leak in caching code\n- **15:35**: Decision made to rollback deployment\n- **15:45**: Rollback initiated\n- **16:10**: Rollback complete, services restarting\n- **16:45**: API partially recovered, 30% requests succeeding\n- **17:15**: Database connections stabilized\n- **17:45**: Full service restoration confirmed\n\n### Post-Incident\n- **18:00**: Customer communication sent\n- **18:30**: Internal post-mortem scheduled\n- **Jan 16**: Full RCA document published\n\n---\n\n## Impact Analysis\n\n### Customer Impact\n- **Total Customers Affected**: 2,847 (100%)\n- **Failed API Requests**: ~487,000\n- **Support Tickets Created**: 142\n- **Escalations**: 23 enterprise customers\n- **Customer Sentiment**: NPS dropped from 42 to 31\n\n### Business Impact\n- **Direct Revenue Loss**: $45K (refunds, SLA credits)\n- **Indirect Costs**: ~$30K (engineering time, support overtime)\n- **Reputation**: 12 churn threats, 3 delayed expansions\n- **Media Coverage**: 2 tech blogs covered the outage\n\n### Technical Impact\n- **Services Down**: API, Dashboard, Mobile Apps\n- **Data Loss**: None (confirmed)\n- **Database Recovery**: Required manual intervention\n\n---\n\n## Root Cause Analysis (5 Whys)\n\n**Problem**: API was completely unavailable for 3h 22min\n\n1. **Why?** Database connection pool was exhausted\n   - *Why?* Application was leaking connections\n\n2. **Why?** Connections weren't being properly released\n   - *Why?* New caching layer had a bug in error handling\n\n3. **Why?** Error handling bug wasn't caught in testing\n   - *Why?* Load testing didn't simulate error conditions\n\n4. **Why?** Load tests were incomplete\n   - *Why?* No chaos engineering or error injection in test plan\n\n5. **Why?** Chaos engineering not standard practice\n   - *Why?* Lack of SRE practices and ownership\n\n**Root Cause**: Insufficient testing of error paths combined with lack of chaos engineering practices.\n\n---\n\n## What Went Wrong\n\n### Technical Failures\n\n#### 1. Code Quality\n- **Issue**: Memory leak in caching layer error handler\n- **Code**: Failed to close Redis connections on timeout\n- **How It Slipped Through**: \n  - Unit tests only covered happy path\n  - Integration tests didn't simulate Redis failures\n  - Code review missed error handling gap\n\n#### 2. Testing Gaps\n- **Issue**: Load testing insufficient\n- **Missing Coverage**:\n  - No error injection (Redis failures)\n  - No sustained load tests (>2 hours)\n  - No memory leak detection\n  - No connection pool stress testing\n\n#### 3. Monitoring Blind Spots\n- **Issue**: Memory increase dismissed as \"normal\"\n- **Missing Alerts**:\n  - No alert on connection pool saturation\n  - No alert on memory growth rate\n  - No automatic rollback on error rate spike\n\n### Process Failures\n\n#### 4. Deployment Practices\n- **Issue**: Deployed to 100% of production immediately\n- **No Safeguards**:\n  - No canary deployment (deploy to 5% first)\n  - No gradual rollout\n  - No automatic rollback on errors\n  - Deployed on Monday (high traffic day)\n\n#### 5. Incident Response\n- **Issue**: 57-minute delay to identify root cause\n- **Contributing Factors**:\n  - No runbook for database connection issues\n  - Log correlation was manual and slow\n  - Rollback decision delayed by debate\n  - War room lacked clear commander\n\n---\n\n## What Went Right\n\n### Effective Actions\n\n1. **Quick Incident Declaration** (5 minutes from first alert)\n   - Enabled rapid response mobilization\n   - Clear escalation path worked\n\n2. **Data Integrity Maintained**\n   - Database failsafes prevented corruption\n   - No customer data loss\n\n3. **Communication** \n   - Status page updated within 10 minutes\n   - Hourly customer updates\n   - Transparent post-incident communication\n\n4. **Team Coordination**\n   - Engineers dropped everything to help\n   - Support team managed customer concerns well\n   - Leadership stayed out of the way\n\n---\n\n## Action Items\n\n### Immediate (This Week)\n\n| Priority | Action | Owner | Due | Success Metric |\n|----------|--------|-------|-----|----------------|\n| P0 | Add connection pool saturation alerts | DevOps | Jan 19 | Alert fires at 80% pool usage |\n| P0 | Create database incident runbook | SRE | Jan 19 | <30min to diagnose similar issues |\n| P0 | Fix caching layer error handling | Backend | Jan 18 | All error paths release connections |\n| P0 | Add memory leak detection to CI | Platform | Jan 19 | Catches leaks before merge |\n\n### Short-term (Next 2 Weeks)\n\n| Priority | Action | Owner | Due | Success Metric |\n|----------|--------|-------|-----|----------------|\n| P1 | Implement canary deployments | DevOps | Jan 30 | 5% canary for 30min before full rollout |\n| P1 | Add error injection to load tests | QA | Jan 30 | Tests include Redis/DB failures |\n| P1 | Create incident commander rotation | SRE | Jan 26 | Clear leader for every incident |\n| P1 | Extend load test duration to 6 hours | QA | Jan 30 | Catches slow leaks |\n| P1 | Add automatic rollback on error spikes | DevOps | Feb 2 | Rollback if errors >5% for 5min |\n\n### Medium-term (Next Quarter)\n\n| Priority | Action | Owner | Due | Success Metric |\n|----------|--------|-------|-----|----------------|\n| P2 | Implement chaos engineering practice | SRE | Mar 15 | Monthly gamedays |\n| P2 | Connection pool right-sizing analysis | Backend | Feb 15 | Optimal pool sizes documented |\n| P2 | Enhanced monitoring dashboard | DevOps | Feb 28 | Single pane for system health |\n| P2 | Deploy time restrictions | Leadership | Feb 1 | No deploys Mon AM or Fri PM |\n\n### Long-term (Next 6 Months)\n\n| Priority | Action | Owner | Due | Success Metric |\n|----------|--------|-------|-----|----------------|\n| P3 | Hire dedicated SRE | Leadership | Apr 30 | Reliability ownership |\n| P3 | Implement multi-region failover | Platform | Jun 30 | <5min regional failover |\n| P3 | Build comprehensive observability | DevOps | May 31 | Distributed tracing, full logging |\n\n---\n\n## Lessons Learned\n\n### Technical Lessons\n\n1. **Error paths are as important as happy paths**\n   - Test what happens when dependencies fail\n   - Error handling must release all resources\n   - Chaos engineering should be standard\n\n2. **Monitoring must be proactive, not reactive**\n   - Alert on trends, not just thresholds\n   - Connection pools should alert at 80%\n   - Memory growth rate matters\n\n3. **Deployment safety requires multiple layers**\n   - Canary deployments (5% ‚Üí 50% ‚Üí 100%)\n   - Automatic rollback on errors\n   - Deploy during low-traffic windows\n\n### Process Lessons\n\n4. **Incident response needs clear ownership**\n   - Designate incident commander\n   - Pre-define decision-making authority\n   - Practice with gamedays\n\n5. **Runbooks are invaluable during incidents**\n   - Create runbooks for common failure modes\n   - Keep them updated and accessible\n   - Include decision trees\n\n6. **Speed matters more than perfection**\n   - Rollback earlier rather than debugging in prod\n   - \"Fix forward\" is risky under pressure\n   - Practice rollback procedures\n\n### Cultural Lessons\n\n7. **Blameless post-mortems enable learning**\n   - Focus on systems, not people\n   - Assume everyone did their best\n   - Psychological safety is critical\n\n8. **Near-misses are warnings**\n   - The memory increase at 14:00 was a signal\n   - Create a culture of investigating anomalies\n   - \"It's probably fine\" is dangerous\n\n---\n\n## Preventive Measures\n\n### Detection\n- Connection pool saturation alerts\n- Memory growth rate alerts\n- Error rate automatic rollback\n- Enhanced observability dashboard\n\n### Prevention\n- Canary deployment (gradual rollout)\n- Error injection in load tests\n- Extended load test duration (6h)\n- Memory leak detection in CI\n- Chaos engineering practice\n\n### Response\n- Incident runbooks for common issues\n- Incident commander rotation\n- Faster rollback procedures\n- War room protocols\n\n---\n\n## Retrospective Metrics\n\n### How We'll Measure Improvement\n\n- **MTTR (Mean Time To Recovery)**: Target <30min (was 202min)\n- **MTTD (Mean Time To Detect)**: Target <5min (was 2min - good)\n- **MTTI (Mean Time To Identify)**: Target <15min (was 57min)\n- **Deployment Success Rate**: Target >99% (was 97%)\n- **Incident-Free Deploys**: Target 95% canary success\n\n### Action Item Completion\n- **Weekly Review**: Track progress on all action items\n- **30-Day Check**: Review P0 and P1 completion\n- **90-Day Retro**: Assess if changes prevented similar issues\n\n---\n\n## Acknowledgments\n\nThank you to everyone who responded to this incident:\n- **Incident Commander**: Alex Chen\n- **Engineering Response**: 12 engineers (6 off-duty joined)\n- **Support Team**: Handled 142 tickets with grace\n- **Leadership**: Provided resources and cover\n\n**This was a team effort. We failed as a system, we'll improve as a system.**\n\n---\n\n## References\n\n- Incident Slack Channel: #incident-2024-001\n- Monitoring Dashboards: [Datadog Incident View]\n- Code Changes: PR #3421 (rolled back)\n- Customer Communication: [Status Page Archive]\n```\n\n---\n\n### Example 3: Quarterly Team Health Retrospective\n\n**User Request**: \"Create a Q4 retrospective for our team. We've had high turnover and want to understand team dynamics and morale.\"\n\n**Assistant Response**:\n\n```markdown\n# Q4 2023 Team Health Retrospective\n## Engineering Team: Data Platform\n\n### Quarter Overview\n- **Team Size**: Started with 12, ended with 9 (3 departures)\n- **Projects Delivered**: 7/10 planned (70%)\n- **Average Team Sentiment**: 5.8/10 (down from 7.2 in Q3)\n- **Turnover Rate**: 25% (company avg: 8%)\n\n---\n\n## Sailboat Retrospective Framework\n\n### The Island (Our Goals)\n*Where we're trying to go*\n\n#### Q4 Goals - Results\n- ‚úÖ Launch real-time data pipeline (ACHIEVED)\n- ‚úÖ Migrate to Snowflake (ACHIEVED)\n- ‚ùå Reduce query latency by 50% (only 20% improvement)\n- ‚ùå Implement data governance framework (60% complete)\n- ‚ùå Build ML feature store (deprioritized due to staffing)\n\n#### Looking Ahead - Q1 Goals\n- Rebuild team morale and stability\n- Complete data governance implementation\n- Reduce on-call burden\n- Improve documentation and knowledge sharing\n\n### The Wind (What's Helping)\n*Forces pushing us toward our goals*\n\n#### Technical Strengths\n- **Modern Tech Stack** (8 mentions)\n  - \"Snowflake migration was smooth, great tooling\"\n  - \"Working with cutting-edge data tech is exciting\"\n  - Impact: Easier to hire, better performance\n\n- **Interesting Problems** (6 mentions)\n  - \"Real-time pipeline work was challenging in a good way\"\n  - \"Data scale is impressive, good learning opportunity\"\n  - Impact: Intellectual engagement, resume building\n\n#### Team Strengths\n- **Talented Colleagues** (7 mentions)\n  - \"Team members are incredibly smart and helpful\"\n  - \"Learn something new from teammates every week\"\n  - Impact: Skills development, problem-solving\n\n- **Autonomy** (5 mentions)\n  - \"Freedom to choose implementation approaches\"\n  - \"Trust to make technical decisions\"\n  - Impact: Ownership, creativity\n\n### The Anchor (What's Holding Us Back)\n*Forces preventing progress*\n\n#### Critical Issues\n\n##### 1. Unrealistic Expectations (9 mentions - HIGHEST)\n- **Feedback**:\n  - \"We're asked to do 12 months of work in 6 months\"\n  - \"Constant pressure to do more with less\"\n  - \"Feel set up to fail with timelines\"\n- **Impact**: Burnout, quality compromises, missed deadlines\n- **Root Cause**: Leadership disconnect on team capacity\n- **Action Required**: URGENT - Reset expectations\n\n##### 2. On-Call Burden (8 mentions)\n- **Feedback**:\n  - \"On-call every other week is unsustainable\"\n  - \"5 incidents last week alone, can't focus on projects\"\n  - \"Sleep deprivation affecting health\"\n- **Impact**: Work-life balance, health, turnover\n- **Root Cause**: System reliability issues + small team\n- **Action Required**: URGENT - Reduce incidents, expand rotation\n\n##### 3. Turnover Impact (7 mentions)\n- **Feedback**:\n  - \"Lost 3 senior engineers in 2 months, we're drowning\"\n  - \"Constantly training new people or covering gaps\"\n  - \"Knowledge left with departed teammates\"\n- **Impact**: Productivity loss, morale decline, quality risk\n- **Root Cause**: Departures creating vicious cycle\n- **Action Required**: URGENT - Stop the bleeding\n\n##### 4. Lack of Recognition (6 mentions)\n- **Feedback**:\n  - \"We delivered 2 huge projects but no acknowledgment\"\n  - \"Feel like we're just a cost center\"\n  - \"Compensation not keeping pace with market\"\n- **Impact**: Motivation, retention, engagement\n- **Root Cause**: Leadership not celebrating wins\n- **Action Required**: Immediate recognition, comp review\n\n##### 5. Poor Communication from Leadership (6 mentions)\n- **Feedback**:\n  - \"Decisions made without consulting us\"\n  - \"Strategy changes monthly, hard to plan\"\n  - \"Feel out of the loop on company direction\"\n- **Impact**: Frustration, misalignment, wasted effort\n- **Root Cause**: Top-down communication gaps\n- **Action Required**: Establish regular communication\n\n#### Medium Issues\n\n##### 6. Meeting Overload (5 mentions)\n- **Feedback**: \"4 hours of meetings daily, when do I code?\"\n- **Impact**: Fragmented time, lower productivity\n\n##### 7. Unclear Priorities (5 mentions)\n- **Feedback**: \"Everything is P0, nothing is truly prioritized\"\n- **Impact**: Thrashing, context switching\n\n##### 8. Technical Debt (4 mentions)\n- **Feedback**: \"We keep building on shaky foundations\"\n- **Impact**: Incidents, slower development\n\n### The Rocks (Risks Ahead)\n*Potential dangers on the horizon*\n\n#### Immediate Risks (Next 30 Days)\n\n##### 1. Further Attrition\n- **Risk**: 2-3 more engineers may leave\n- **Indicators**: \n  - 3 team members updating LinkedIn\n  - 2 verbal hints about \"exploring options\"\n  - Exit interview patterns match current concerns\n- **Impact**: Team collapse, project failures\n- **Mitigation**: URGENT - Stay interviews, address concerns\n\n##### 2. Burnout Epidemic\n- **Risk**: Remaining team burning out\n- **Indicators**:\n  - Average work week: 55 hours\n  - Vacation days taken: 30% below company average\n  - Sick days up 40%\n- **Impact**: Quality decline, health issues, turnover\n- **Mitigation**: Mandatory time off, workload reduction\n\n##### 3. Production Incidents\n- **Risk**: Critical system failure due to understaffing\n- **Indicators**:\n  - Incident rate up 60%\n  - Monitoring gaps due to lack of time\n  - Technical debt accumulating\n- **Impact**: Customer impact, reputation damage\n- **Mitigation**: Freeze new features, focus on stability\n\n#### Medium-term Risks (Next Quarter)\n\n##### 4. Knowledge Loss\n- **Risk**: Critical knowledge only with 1-2 people\n- **Mitigation**: Documentation sprints, pairing\n\n##### 5. Recruitment Challenges\n- **Risk**: Reputation affecting hiring\n- **Mitigation**: Improve Glassdoor reviews, referrals\n\n---\n\n## Anonymous Team Survey Results\n*(10 responses out of 12 team members)*\n\n### Quantitative Results\n\n| Question | Q3 Score | Q4 Score | Change |\n|----------|----------|----------|--------|\n| Overall job satisfaction | 7.2/10 | 5.8/10 | -1.4 ‚¨áÔ∏è |\n| Work-life balance | 6.5/10 | 4.2/10 | -2.3 ‚¨áÔ∏è‚¨áÔ∏è |\n| Confidence in leadership | 6.8/10 | 4.5/10 | -2.3 ‚¨áÔ∏è‚¨áÔ∏è |\n| Team collaboration | 8.1/10 | 7.2/10 | -0.9 ‚¨áÔ∏è |\n| Growth opportunities | 7.5/10 | 6.8/10 | -0.7 ‚¨áÔ∏è |\n| Compensation satisfaction | 6.2/10 | 5.1/10 | -1.1 ‚¨áÔ∏è |\n| Would recommend company | 70% | 40% | -30% ‚¨áÔ∏è‚¨áÔ∏è |\n\n### Qualitative Feedback\n\n**What would make you consider leaving?**\n- \"Continued unrealistic expectations\" (6 responses)\n- \"No work-life balance improvement\" (5 responses)\n- \"Another teammate leaving\" (4 responses)\n- \"No compensation adjustment\" (3 responses)\n\n**What would make you stay?**\n- \"Realistic workload and timelines\" (7 responses)\n- \"Better compensation\" (6 responses)\n- \"Team stability\" (5 responses)\n- \"Leadership listening and acting\" (4 responses)\n\n---\n\n## Action Items\n\n### Emergency Actions (This Week)\n\n| Priority | Action | Owner | Due | Success Metric |\n|----------|--------|-------|-----|----------------|\n| P0 | Conduct stay interviews with all 9 team members | Engineering Director | Dec 22 | 100% completion, concerns documented |\n| P0 | Pause all new feature work for 2 weeks | VP Engineering | Dec 20 | Team focused on stability only |\n| P0 | Emergency compensation review | HR + Director | Dec 23 | Market adjustments for retention risks |\n| P0 | Expand on-call rotation (include adjacent teams) | Engineering Manager | Dec 21 | Max 1 week/month per person |\n\n### Critical Actions (Next 2 Weeks)\n\n| Priority | Action | Owner | Due | Success Metric |\n|----------|--------|-------|-----|----------------|\n| P1 | Reset Q1 roadmap with team input | Product + Eng Dir | Jan 5 | Realistic scope, team buy-in |\n| P1 | Implement \"No Meeting Wednesdays\" | Engineering Manager | Jan 3 | 80% reduction in Wed meetings |\n| P1 | Create incident reduction task force | SRE + Team | Jan 10 | 50% incident reduction target |\n| P1 | Weekly leadership office hours | Engineering Director | Jan 2 | 2 hours/week, open Q&A |\n| P1 | Celebrate Q4 wins (team dinner, bonuses) | Director + HR | Jan 5 | Team feels appreciated |\n\n### Short-term Actions (Next 30 Days)\n\n| Priority | Action | Owner | Due | Success Metric |\n|----------|--------|-------|-----|----------------|\n| P2 | Hire 2 senior engineers | Recruiting | Jan 31 | Offers extended |\n| P2 | Knowledge sharing documentation sprint | Team | Jan 15 | Critical systems documented |\n| P2 | Establish priority framework (not everything P0) | Product | Jan 10 | Clear P0/P1/P2 definitions |\n| P2 | Team offsite for morale and planning | Engineering Manager | Jan 20 | Team bonding, strategic alignment |\n\n---\n\n## Retrospective Commitments from Leadership\n\n### From Engineering Director\n\n\"I hear you. The expectations were unrealistic, the recognition was insufficient, and the communication was poor. Here's what I commit to:\n\n1. **Transparency**: Monthly all-hands on team strategy and priorities\n2. **Reasonable Scope**: No more overloaded roadmaps. We'll plan for 70% capacity.\n3. **Recognition**: Quarterly team celebrations, public acknowledgment of wins\n4. **Career Growth**: Individual development plans for everyone by end of Q1\n5. **Your Voice**: This won't be the last retro. Monthly pulse checks starting January.\n\nI take responsibility for the Q4 situation. Let's make Q1 different.\"\n\n### From VP Engineering\n\n\"The turnover rate is unacceptable and unsustainable. I'm committing executive support:\n\n1. **Budget**: Approved comp adjustments and 2 additional headcount\n2. **Priority**: Data Platform is now a top-3 company priority\n3. **Support**: Bi-weekly check-ins with me, no bureaucracy\n4. **Protection**: I'll shield you from unrealistic requests\n\nThis team is critical to our success. Let's rebuild trust together.\"\n\n---\n\n## Success Metrics for Q1\n\n### Team Health\n- **Target Satisfaction**: 7.5/10 (from 5.8)\n- **Target Work-Life Balance**: 7.0/10 (from 4.2)\n- **Target Turnover**: 0 departures\n- **Vacation Utilization**: 100% of accrued days\n\n### Operational\n- **On-call Frequency**: Max 1 week/month (from 2 weeks/month)\n- **Incident Rate**: Reduce by 50%\n- **Meeting Hours**: <15 hours/week (from 20)\n\n### Delivery\n- **Roadmap**: 100% of Q1 scope (realistic scope)\n- **Technical Debt**: 20% reduction\n- **Documentation**: 90% of critical systems documented\n\n---\n\n## Follow-up Plan\n\n- **Weekly**: Check action item progress\n- **Bi-weekly**: Leadership office hours\n- **Monthly**: Team pulse survey (3 questions, 5 min)\n- **End of Q1**: Full team health retrospective\n\n---\n\n## Lessons Learned\n\n1. **Team health is a leading indicator**: Morale declined before turnover\n2. **Small teams need protection**: Can't absorb unrealistic demands\n3. **Recognition matters**: Lack of appreciation directly correlates with attrition\n4. **Communication is critical**: Transparency builds trust\n5. **Act on feedback quickly**: Delayed action amplifies problems\n\n**The team told us what was wrong. Now we must act.**\n```\n\n---\n\n## Best Practices\n\n### Running Effective Retrospectives\n\n1. **Create Psychological Safety**\n   - Emphasize blameless culture\n   - Use anonymous input tools\n   - Model vulnerability as facilitator\n   - Focus on systems, not individuals\n\n2. **Use Timeboxing**\n   - Stick to the schedule\n   - Prevent discussion from derailing\n   - Respect everyone's time\n\n3. **Make Actions Concrete**\n   - Specific, not vague (\"improve communication\" ‚Üí \"daily standup notes in Slack\")\n   - Assign clear owners\n   - Set realistic due dates\n   - Limit to 3-5 high-impact actions\n\n4. **Track Trends**\n   - Look for recurring themes\n   - Measure sentiment over time\n   - Review previous action items\n\n5. **Follow Through**\n   - Review action items at next retro\n   - Celebrate completed improvements\n   - Be transparent about incomplete items\n\n### Common Pitfalls to Avoid\n\n- **Skipping retros**: \"Too busy\" leads to repeated mistakes\n- **No action items**: Discussion without action wastes time\n- **Too many actions**: Overwhelming, nothing gets done\n- **Blaming individuals**: Destroys psychological safety\n- **Same format every time**: Fatigue, reduced engagement\n- **Not tracking completion**: Actions become hollow promises\n\n## Retrospective Format Guide\n\n### Quick Reference\n\n- **Start-Stop-Continue**: Best for regular sprints, simple and effective\n- **Sailboat**: Visual, good for goal-oriented teams\n- **4Ls**: Comprehensive, good for project closures\n- **Mad-Sad-Glad**: Emotion-focused, good for team dynamics\n- **Timeline**: Best for incidents or complex projects\n- **Lean Coffee**: Democratic, team-driven agenda\n",
  "prompt": "A skill that facilitates effective sprint retrospectives, captures action items, and synthesizes team feedback for continuous improvement. Supports multiple retrospective formats including Start-Stop-Continue, Sailboat, 4Ls, and Mad-Sad-Glad. Generates comprehensive retrospective documents with metrics, action items, and improvement tracking. Perfect for agile teams, project post-mortems, and team health assessments.",
  "createdAt": "2024-01-15T10:00:00.000Z",
  "published": true
}
