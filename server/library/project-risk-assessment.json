{
  "id": "project-risk-assessment",
  "name": "project-risk-assessment",
  "description": "Conduct thorough risk analysis, develop mitigation strategies, and create contingency plans for projects",
  "category": "Project",
  "content": "---\nname: project-risk-assessment\ndescription: Conduct thorough risk analysis, develop mitigation strategies, and create contingency plans for projects\ncategory: Project\n---\n\n# Project Risk Assessment & Mitigation\n\n## Overview\n\nThis skill helps identify, analyze, and mitigate project risks using industry-standard frameworks including RAID (Risks, Assumptions, Issues, Dependencies), risk matrices, failure mode analysis, and pre-mortem techniques. It generates comprehensive risk registers, mitigation plans, and contingency strategies to increase project success rates and reduce unexpected failures.\n\n## Activation\n\nThis skill activates when users request:\n- Risk assessment or risk analysis\n- Risk registers or RAID logs\n- Mitigation strategies or contingency plans\n- Pre-mortem or failure analysis\n- Project risk management\n- Dependency mapping\n- Assumption validation\n- Issue tracking and escalation\n\n## Instructions\n\n### Conducting Risk Assessment\n\n1. **Identify Risks**\n   - Brainstorm with team (what could go wrong?)\n   - Review similar past projects\n   - Analyze dependencies and assumptions\n   - Consider technical, organizational, and external risks\n\n2. **Analyze and Prioritize**\n   - **Probability**: How likely is this to happen? (Low/Medium/High or 1-5)\n   - **Impact**: If it happens, how bad is it? (Low/Medium/High or 1-5)\n   - **Risk Score**: Probability Ã— Impact\n   - **Priority**: Focus on high-probability, high-impact risks first\n\n3. **Develop Mitigation Strategies**\n   - **Avoid**: Change plans to eliminate the risk\n   - **Mitigate**: Reduce probability or impact\n   - **Transfer**: Shift responsibility (insurance, outsourcing)\n   - **Accept**: Acknowledge and monitor (for low-priority risks)\n\n4. **Create Contingency Plans**\n   - \"If X happens, we will do Y\"\n   - Identify triggers and early warning signs\n   - Assign owners and response procedures\n   - Set aside contingency budget and time\n\n5. **Monitor and Update**\n   - Review risk register weekly\n   - Track risk trends (increasing/decreasing)\n   - Add new risks as they emerge\n   - Archive resolved risks\n\n### Risk Assessment Frameworks\n\n#### RAID Log\n- **R**isks: Future events that might happen\n- **A**ssumptions: Things we believe to be true\n- **I**ssues: Current problems affecting the project\n- **D**ependencies: External factors we rely on\n\n#### Risk Matrix (Probability Ã— Impact)\n\n```\nImpact â†’     Low(1)  Medium(2)  High(3)  Critical(4)\nProbability â†“\nHigh (4)      4        8         12        16\nMedium (3)    3        6          9        12\nLow (2)       2        4          6         8\nRare (1)      1        2          3         4\n\nPriority:\n12-16: Critical (immediate action)\n6-11: High (active mitigation)\n3-5: Medium (monitor closely)\n1-2: Low (accept and document)\n```\n\n#### Pre-Mortem Technique\n\n\"Imagine it's 6 months from now and the project has failed spectacularly. What went wrong?\"\n\nThis technique reveals risks that traditional brainstorming misses.\n\n## Examples\n\n### Example 1: Software Product Launch Risk Assessment\n\n**User Request**: \"We're launching our new SaaS platform in 3 months. Help me identify and plan for potential risks.\"\n\n**Assistant Response**:\n\n```markdown\n# Risk Assessment: SaaS Platform Launch\n## Project: Customer Analytics Platform v2.0\n**Launch Date**: April 1, 2024 (12 weeks from now)\n**Last Updated**: January 15, 2024\n\n---\n\n## Executive Summary\n\n### Risk Overview\n- **Total Risks Identified**: 18\n- **Critical Priority**: 3 risks (requires immediate action)\n- **High Priority**: 5 risks (active mitigation needed)\n- **Medium Priority**: 7 risks (monitoring required)\n- **Low Priority**: 3 risks (accepted)\n\n### Top 3 Risks\n1. **Data migration failure** (Risk Score: 16) - Could delay launch by 4-6 weeks\n2. **Third-party API dependency** (Risk Score: 12) - Could break core features\n3. **Performance under load** (Risk Score: 12) - Could cause launch-day outage\n\n### Overall Risk Health\nğŸ”´ **HIGH RISK** - Multiple critical risks require immediate mitigation before launch\n\n**Recommendation**: Consider pushing launch by 2-4 weeks to properly mitigate critical risks.\n\n---\n\n## RAID Log\n\n### Risks (Future Events)\n\n#### CRITICAL PRIORITY (Score: 12-16)\n\n##### R-001: Data Migration from v1 to v2 Fails\n- **Category**: Technical\n- **Probability**: Medium (3/4) - Complex migration, limited testing\n- **Impact**: Critical (4/4) - 50K customers unable to access data\n- **Risk Score**: 12\n- **Owner**: Sarah Chen (Data Engineering Lead)\n- **Status**: ğŸ”´ Open\n\n**Description**: \nMigrating 500GB of customer data from legacy MongoDB to new PostgreSQL schema. Schema changes are significant and data transformation is complex.\n\n**Impact Analysis**:\n- Launch delay: 4-6 weeks to fix and re-migrate\n- Customer churn: 10-15% of users abandon platform\n- Revenue impact: $200K-$500K lost ARR\n- Reputation damage: Negative reviews, social media backlash\n\n**Mitigation Strategy**:\n1. **Reduce Probability**:\n   - Run migration dry-runs in staging (weekly, starting now)\n   - Build comprehensive data validation suite\n   - Create rollback procedure (max 1-hour downtime)\n   - Hire external migration consultant for review\n   \n2. **Reduce Impact**:\n   - Migrate in phases (10% of users per day over 10 days)\n   - Keep v1 running in read-only mode for 30 days\n   - Create customer communication plan\n   - Set up 24/7 support war room during migration\n\n**Contingency Plan**:\n- **Trigger**: >5% data validation failures in dry-run\n- **Action**: \n  1. Halt migration immediately\n  2. Rollback to v1 (documented procedure)\n  3. Delay launch by 2 weeks to fix issues\n  4. Communicate transparently with customers\n- **Budget**: $50K contingency for extended AWS costs + consultant\n\n**Early Warning Indicators**:\n- Dry-run failure rate trending up\n- Data validation errors increasing\n- Migration script execution time exceeding estimates\n\n**Timeline**:\n- Week 1-2: Daily dry-run migrations\n- Week 3: External consultant review\n- Week 4-6: Pilot migration (100 test accounts)\n- Week 7-10: Phased production migration\n\n---\n\n##### R-002: Third-Party Payment API (Stripe) Outage or Breaking Change\n- **Category**: External Dependency\n- **Probability**: Medium (3/4) - Stripe has had outages in past year\n- **Impact**: Critical (4/4) - Cannot process payments, revenue loss\n- **Risk Score**: 12\n- **Owner**: Alex Rodriguez (Backend Lead)\n- **Status**: ğŸŸ¡ Mitigating\n\n**Description**:\nWe depend on Stripe API for all payment processing. A Stripe outage or breaking API change during launch could prevent new customer signups.\n\n**Impact Analysis**:\n- Revenue loss: $10K per hour of downtime (peak signup period)\n- Customer frustration: Unable to complete purchase\n- Competitive disadvantage: Customers choose alternatives\n\n**Mitigation Strategy**:\n1. **Reduce Probability** (can't control Stripe uptime):\n   - Subscribe to Stripe status webhooks\n   - Monitor Stripe API changelog for breaking changes\n   - Pin to specific Stripe API version (don't auto-upgrade)\n\n2. **Reduce Impact**:\n   - Implement circuit breaker pattern (fail gracefully)\n   - Build \"save for later\" feature if payment temporarily unavailable\n   - Queue failed payments for retry\n   - Set up email capture for users who couldn't complete signup\n\n3. **Transfer Risk**:\n   - Add backup payment processor (PayPal) for redundancy\n   - Negotiate SLA with Stripe (enterprise plan)\n\n**Contingency Plan**:\n- **Trigger**: Stripe status page shows outage or elevated error rates\n- **Action**:\n  1. Display customer-friendly error message\n  2. Capture email addresses to follow up when resolved\n  3. Activate PayPal as backup within 1 hour\n  4. Communicate via social media and status page\n- **Budget**: $20K for PayPal integration (already scoped)\n\n**Current Status**: \n- âœ… Circuit breaker implemented\n- âœ… Stripe webhook monitoring active\n- ğŸ”„ PayPal backup integration 60% complete (due Feb 15)\n- â³ Email capture feature not started (2 days of work)\n\n---\n\n##### R-003: Performance Degradation Under Launch Traffic\n- **Category**: Technical\n- **Probability**: Medium (3/4) - Untested at scale\n- **Impact**: Critical (4/4) - Launch day outage, bad first impression\n- **Risk Score**: 12\n- **Owner**: DevOps Team\n- **Status**: ğŸ”´ Open\n\n**Description**:\nWe expect 10K concurrent users on launch day (10x normal traffic). System hasn't been load-tested at this scale. Database, API, or frontend could become bottlenecks.\n\n**Impact Analysis**:\n- Launch day failure: Viral negative publicity\n- Lost momentum: Product Hunt launch wasted\n- Customer trust: \"If it fails on day 1, what about production use?\"\n- Delayed revenue: Can't convert launch traffic\n\n**Mitigation Strategy**:\n1. **Reduce Probability**:\n   - Conduct load testing at 15K concurrent users (150% of expected)\n   - Implement auto-scaling (API servers and database read replicas)\n   - Set up CDN for static assets (Cloudflare)\n   - Add Redis caching layer for frequently accessed data\n   - Database query optimization (review slow query log)\n\n2. **Reduce Impact**:\n   - Prepare scaled-down \"launch mode\" (disable non-essential features)\n   - Set up rate limiting to prevent cascading failures\n   - Create incident response playbook\n   - Have engineering team on standby during launch\n\n**Contingency Plan**:\n- **Trigger**: Response time >3 seconds or error rate >1%\n- **Action**:\n  1. Enable \"launch mode\" (disable widgets, reduce features)\n  2. Increase server capacity manually (1-click runbook)\n  3. Display maintenance page if needed\n  4. Throttle new signups if database overwhelmed\n- **Budget**: $15K contingency for additional AWS capacity\n\n**Load Testing Plan**:\n- **Week 8**: Baseline test (1K concurrent users)\n- **Week 9**: Stress test (5K concurrent users)\n- **Week 10**: Peak test (15K concurrent users)\n- **Week 11**: Soak test (24-hour sustained load)\n- **Week 12**: Final validation\n\n**Current Status**:\n- â³ Load testing not started (high priority!)\n- âœ… Auto-scaling configured\n- âœ… CDN set up\n- ğŸ”„ Redis caching 40% complete\n\n---\n\n#### HIGH PRIORITY (Score: 9-11)\n\n##### R-004: Key Engineer Leaves Before Launch\n- **Probability**: Low (2/4)\n- **Impact**: High (3/4)\n- **Risk Score**: 6 â†’ **Escalated to 9** (team morale indicator)\n- **Owner**: Engineering Manager\n\n**Mitigation**:\n- Stay interviews with critical team members\n- Knowledge sharing sessions (no single points of failure)\n- Pair programming on critical components\n- Documentation of all systems\n- Retention bonuses tied to launch success\n\n**Contingency**: \n- Contractor on standby ($200/hour, 2-week notice)\n- Cross-training completed\n\n---\n\n##### R-005: Security Vulnerability Discovered Pre-Launch\n- **Probability**: Medium (3/4)\n- **Impact**: High (3/4)\n- **Risk Score**: 9\n- **Owner**: Security Team\n\n**Mitigation**:\n- External penetration test (scheduled Week 9)\n- Security code review by third party\n- Automated vulnerability scanning (Snyk, Dependabot)\n- Bug bounty program soft launch\n\n**Contingency**:\n- Delay launch if critical vulnerability found\n- Have security firm on retainer for rapid response\n\n---\n\n##### R-006: Marketing Campaign Fails to Drive Traffic\n- **Probability**: Medium (3/4)\n- **Impact**: Medium (2/4)\n- **Risk Score**: 6 â†’ **Escalated to 9** (business critical)\n- **Owner**: Marketing Director\n\n**Mitigation**:\n- Diversified marketing channels (Product Hunt, HN, paid ads, email)\n- Pre-launch waitlist (5K emails already captured)\n- Partner with influencers (3 confirmed)\n- Backup PR agency identified\n\n**Contingency**:\n- Increase ad spend by $20K if organic reach is low\n- Extend launch campaign from 1 week to 3 weeks\n\n---\n\n##### R-007: Compliance Issue (GDPR/SOC2) Blocks Enterprise Sales\n- **Probability**: Low (2/4)\n- **Impact**: Critical (4/4)\n- **Risk Score**: 8 â†’ **Escalated to 9**\n- **Owner**: Legal & Compliance\n\n**Mitigation**:\n- External compliance audit (scheduled Week 7)\n- GDPR compliance checklist review\n- SOC 2 Type 1 certification in progress\n- DPA templates prepared\n\n**Contingency**:\n- Launch to SMB market first, delay enterprise sales\n- Hire compliance consultant if audit reveals gaps\n\n---\n\n##### R-008: Browser Compatibility Issues\n- **Probability**: Medium (3/4)\n- **Impact**: Medium (2/4)\n- **Risk Score**: 6 â†’ **Escalated to 9** (poor UX)\n- **Owner**: Frontend Lead\n\n**Mitigation**:\n- Cross-browser testing (Chrome, Firefox, Safari, Edge)\n- BrowserStack automated testing\n- Polyfills for older browsers\n- Graceful degradation for IE11 (if required)\n\n**Contingency**:\n- Display browser upgrade notice\n- Focus testing on top 3 browsers (95% of users)\n\n---\n\n#### MEDIUM PRIORITY (Score: 4-8)\n\n##### R-009: Documentation Incomplete at Launch\n- **Probability**: High (4/4)\n- **Impact**: Low (2/4)\n- **Risk Score**: 8\n- **Mitigation**: Documentation sprint in Week 11, technical writer hired\n\n##### R-010: Customer Support Overwhelmed\n- **Probability**: Medium (3/4)\n- **Impact**: Medium (2/4)\n- **Risk Score**: 6\n- **Mitigation**: Hire 2 temp support agents, create FAQ, chatbot for common questions\n\n##### R-011: Mobile App Not Ready (Nice-to-Have)\n- **Probability**: High (4/4)\n- **Impact**: Low (1/4)\n- **Risk Score**: 4\n- **Mitigation**: Delay mobile launch to Q2, focus on web experience\n\n##### R-012: Integrations (Salesforce, HubSpot) Delayed\n- **Probability**: Medium (3/4)\n- **Impact**: Low (2/4)\n- **Risk Score**: 6\n- **Mitigation**: Launch with Zapier integration only, add native integrations post-launch\n\n##### R-013: Pricing Model Confuses Customers\n- **Probability**: Medium (3/4)\n- **Impact**: Medium (2/4)\n- **Risk Score**: 6\n- **Mitigation**: User testing on pricing page (Week 8), simplify tiers\n\n##### R-014: Competitor Launches Similar Feature\n- **Probability**: Low (2/4)\n- **Impact**: Medium (2/4)\n- **Risk Score**: 4\n- **Mitigation**: Differentiate on UX and performance, prepare competitive messaging\n\n##### R-015: Localization/i18n Issues for International Users\n- **Probability**: Medium (3/4)\n- **Impact**: Low (2/4)\n- **Risk Score**: 6\n- **Mitigation**: Launch English-only, add localization in Q2\n\n---\n\n#### LOW PRIORITY (Score: 1-3)\n\n##### R-016: Design Changes Requested Last Minute\n- **Probability**: Low (2/4)\n- **Impact**: Low (1/4)\n- **Risk Score**: 2\n- **Mitigation**: Design freeze on Feb 1, no changes after\n\n##### R-017: Analytics/Tracking Not Fully Implemented\n- **Probability**: Low (2/4)\n- **Impact**: Low (1/4)\n- **Risk Score**: 2\n- **Mitigation**: Core events tracked, nice-to-have events can be added post-launch\n\n##### R-018: Social Media Negative Feedback\n- **Probability**: Low (2/4)\n- **Impact**: Low (1/4)\n- **Risk Score**: 2\n- **Mitigation**: Social media monitoring, prepared response templates\n\n---\n\n### Assumptions\n\n| ID | Assumption | Validated? | Risk if Wrong | Owner |\n|----|------------|------------|---------------|-------|\n| A-001 | Stripe API remains stable | âš ï¸ No | High | Backend Lead |\n| A-002 | AWS infrastructure scales as expected | âœ… Yes (tested) | Critical | DevOps |\n| A-003 | Target market wants this product | âœ… Yes (user research) | Critical | Product |\n| A-004 | Team has capacity for 60-hour weeks pre-launch | âš ï¸ No | Medium | Manager |\n| A-005 | No major holidays during launch window | âœ… Yes | Low | Marketing |\n| A-006 | Budget ($200K) is sufficient | âš ï¸ No | High | Finance |\n| A-007 | Legal approves all marketing claims | â³ Pending | Medium | Legal |\n| A-008 | Database migration takes <4 weeks | âš ï¸ No (untested) | Critical | Data Eng |\n\n**Action Required**: Validate all assumptions marked âš ï¸ by Week 6.\n\n---\n\n### Issues (Current Problems)\n\n| ID | Issue | Severity | Impact | Status | Owner | Resolution |\n|----|-------|----------|--------|--------|-------|------------|\n| I-001 | API rate limiting causing test failures | High | Blocks QA | ğŸ”´ Open | Backend | Fix by Jan 20 |\n| I-002 | Design handoff incomplete | Medium | Delays frontend | ğŸŸ¡ In Progress | Design | 80% complete |\n| I-003 | Staging environment unstable | High | Can't demo to investors | ğŸ”´ Open | DevOps | Fix by Jan 18 |\n| I-004 | 2 engineers out sick this week | Medium | Velocity reduced | ğŸŸ¢ Resolving | Manager | Back Jan 17 |\n| I-005 | Budget overrun on AWS costs | Medium | May need more funding | ğŸŸ¡ In Progress | Finance | Meeting Jan 19 |\n\n**Escalation**: I-001 and I-003 are blocking progress. Need immediate attention.\n\n---\n\n### Dependencies\n\n| ID | Dependency | Type | Owner | Status | Risk | Mitigation |\n|----|------------|------|-------|--------|------|------------|\n| D-001 | Stripe API availability | External | Stripe | âœ… Stable | Medium | Backup processor (PayPal) |\n| D-002 | AWS infrastructure | External | AWS | âœ… Stable | Low | Multi-region failover |\n| D-003 | Design team deliverables | Internal | Design | ğŸŸ¡ 80% done | Medium | Extend timeline if needed |\n| D-004 | Legal approval for marketing | Internal | Legal | â³ Pending | High | Follow up Jan 20 |\n| D-005 | Security audit completion | External | SecureCo | â³ Scheduled Week 9 | High | Book backup firm |\n| D-006 | Data migration script from vendor | External | ConsultCo | ğŸ”´ Delayed | Critical | Bring in-house if needed |\n\n**Critical Path**: D-006 is on critical path. Delay here delays entire launch.\n\n---\n\n## Risk Trends\n\n### Risk Velocity (New Risks per Week)\n- Week 1: 5 risks identified\n- Week 2: 3 new risks\n- Week 3: 2 new risks\n- Week 4: 4 new risks (trending up âš ï¸)\n\n**Analysis**: Risk discovery rate increasing. Suggests unknowns emerging as we get closer to launch.\n\n### Risk Closure Rate\n- Resolved: 2 risks\n- Mitigated to acceptable level: 4 risks\n- Still open: 12 risks (67%)\n\n**Analysis**: Not closing risks fast enough. Need to accelerate mitigation efforts.\n\n---\n\n## Pre-Mortem Analysis\n\n**Exercise**: \"It's July 2024. The launch was a disaster. What went wrong?\"\n\n### Team Responses\n\n1. **\"Data migration corrupted customer data, had to rollback, lost trust\"**\n   - Likelihood: Medium\n   - Added as R-001 (already identified)\n\n2. **\"We launched with bugs, customers complained, bad reviews tanked sales\"**\n   - Likelihood: High\n   - Mitigation: Extend QA timeline, bug bash in Week 10\n\n3. **\"Performance was terrible, site crashed on launch day, went viral for wrong reasons\"**\n   - Likelihood: Medium\n   - Added as R-003 (already identified)\n\n4. **\"We ran out of money and had to cut features, launched half-baked product\"**\n   - Likelihood: Low-Medium\n   - Mitigation: Secure additional funding or reduce scope now\n\n5. **\"Key engineer quit 2 weeks before launch, left huge knowledge gap\"**\n   - Likelihood: Low\n   - Added as R-004 (already identified)\n\n6. **\"Marketing fizzled, no one showed up to launch, spent months building for crickets\"**\n   - Likelihood: Medium\n   - Added as R-006 (already identified)\n\n7. **\"Competitor launched same feature 1 week before us, stole our thunder\"**\n   - Likelihood: Low\n   - Added as R-014 (accepted, low priority)\n\n8. **\"We didn't have proper monitoring, couldn't diagnose issues during launch\"**\n   - Likelihood: Medium\n   - **NEW RISK** - Added as R-019\n\n**New Risks from Pre-Mortem**:\n- R-019: Insufficient monitoring and alerting (Score: 9)\n- R-020: Inadequate QA testing (Score: 8)\n\n---\n\n## Risk Mitigation Budget\n\n| Category | Allocated | Spent | Remaining |\n|----------|-----------|-------|----------|\n| Infrastructure (load testing, scaling) | $50K | $15K | $35K |\n| External consultants (migration, security) | $75K | $40K | $35K |\n| Contingency reserve | $30K | $0 | $30K |\n| Additional staffing (contractors) | $25K | $0 | $25K |\n| **Total** | **$180K** | **$55K** | **$125K** |\n\n**Burn Rate**: $13.75K/week. At this rate, we'll spend $165K by launch (within budget).\n\n---\n\n## Action Items\n\n### This Week (Week 5)\n\n| Priority | Action | Owner | Due | Status |\n|----------|--------|-------|-----|--------|\n| P0 | Start load testing (R-003) | DevOps | Jan 19 | Not Started |\n| P0 | Complete PayPal integration (R-002) | Backend | Jan 22 | In Progress |\n| P0 | Run first migration dry-run (R-001) | Data Eng | Jan 20 | Not Started |\n| P1 | Validate assumption A-008 (migration time) | Data Eng | Jan 22 | Not Started |\n| P1 | Resolve I-003 (staging instability) | DevOps | Jan 18 | In Progress |\n| P1 | Follow up on D-006 (vendor delay) | Manager | Jan 17 | Not Started |\n\n### Next 2 Weeks (Weeks 6-7)\n\n- Complete penetration test (R-005)\n- Finish Redis caching implementation (R-003)\n- Conduct user testing on pricing (R-013)\n- Hire temp support agents (R-010)\n- Security audit (D-005)\n\n### Month 2 (Weeks 8-11)\n\n- Phased data migration (R-001)\n- Load testing at scale (R-003)\n- Documentation sprint (R-009)\n- Marketing campaign ramp-up (R-006)\n\n---\n\n## Recommendations\n\n### Immediate Actions\n\n1. **ğŸ”´ CRITICAL: Address R-001 (Data Migration)**\n   - This is the highest impact risk\n   - Start dry-runs immediately\n   - Hire external consultant this week\n   - Consider phased migration starting Week 7\n\n2. **ğŸ”´ CRITICAL: Start Load Testing (R-003)**\n   - Currently no evidence system can handle launch traffic\n   - Week 8 target is too late\n   - Move to Week 5 (this week)\n\n3. **ğŸŸ¡ HIGH: Accelerate Risk Closure**\n   - 67% of risks still open\n   - Assign dedicated \"risk owner\" role\n   - Daily risk review in standup\n\n### Strategic Recommendations\n\n4. **Consider Launch Date Flexibility**\n   - Current risk level is HIGH\n   - Pushing launch 2-4 weeks could significantly reduce risk\n   - Trade-off: Market timing vs. quality\n   - **Decision needed by**: Jan 25\n\n5. **Increase Mitigation Budget**\n   - Several critical risks may need more resources\n   - Recommend increasing budget by $50K\n   - Focus on external expertise (migration, load testing)\n\n6. **Reduce Scope**\n   - Some medium-priority features could be cut\n   - R-011 (mobile), R-012 (integrations), R-015 (localization) are post-launch\n   - Focus on core product excellence\n\n---\n\n## Risk Review Cadence\n\n- **Daily**: Stand-up mention of new/changed risks\n- **Weekly**: Full RAID log review (30 minutes)\n- **Bi-weekly**: Executive risk briefing\n- **Monthly**: Deep-dive risk workshop\n\n**Next Review**: January 19, 2024 (Friday) 2:00 PM\n\n---\n\n## Appendix: Risk Assessment Methodology\n\n### Probability Scale\n- **Rare (1)**: <10% chance\n- **Low (2)**: 10-30% chance\n- **Medium (3)**: 30-60% chance\n- **High (4)**: >60% chance\n\n### Impact Scale\n- **Low (1)**: Minor inconvenience, <1 week delay, <$10K cost\n- **Medium (2)**: Moderate impact, 1-2 week delay, $10K-$50K cost\n- **High (3)**: Major impact, 3-4 week delay, $50K-$150K cost\n- **Critical (4)**: Catastrophic, >4 week delay, >$150K cost, or launch cancellation\n\n### Priority Thresholds\n- **Critical (12-16)**: Drop everything, address immediately\n- **High (9-11)**: Active mitigation, weekly review\n- **Medium (4-8)**: Monitor closely, plan mitigation\n- **Low (1-3)**: Accept and document, monthly review\n\n---\n\n**Document Owner**: Project Manager\n**Last Updated**: January 15, 2024\n**Next Update**: January 22, 2024\n```\n\n---\n\n### Example 2: Infrastructure Migration Risk Analysis\n\n**User Request**: \"We're migrating our entire infrastructure from on-premise to AWS. Assess the risks.\"\n\n**Assistant Response**:\n\n```markdown\n# Risk Assessment: On-Premise to AWS Cloud Migration\n## Project: Infrastructure Modernization Initiative\n**Duration**: 9 months (March - November 2024)\n**Budget**: $1.2M\n**Criticality**: Business-critical (downtime = revenue loss)\n\n---\n\n## Executive Risk Summary\n\n### Risk Heat Map\n\n```\nProbability\n  â†‘\nHigh â”‚     R-003    â”‚   R-001     â”‚             â”‚   R-002\n     â”‚     R-007    â”‚   R-005     â”‚             â”‚\n     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nMed  â”‚              â”‚   R-008     â”‚   R-004     â”‚\n     â”‚              â”‚   R-009     â”‚   R-006     â”‚\n     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nLow  â”‚              â”‚   R-010     â”‚             â”‚\n     â”‚              â”‚             â”‚             â”‚\n     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’\n                  Low        Medium        High        Critical\n                                                     Impact\n```\n\n### Top 5 Risks\n\n1. **R-001**: Extended downtime during cutover (Probability: High, Impact: Critical)\n2. **R-002**: Data loss or corruption (Probability: High, Impact: Critical)\n3. **R-003**: Cost overruns (Probability: High, Impact: Low)\n4. **R-004**: Performance degradation post-migration (Probability: Medium, Impact: High)\n5. **R-005**: Security breach during transition (Probability: High, Impact: Medium)\n\n### Overall Assessment\n\nğŸ”´ **HIGH RISK PROJECT**\n\n- **Complexity**: Very High (30+ services, 200+ servers)\n- **Business Impact**: Critical (customer-facing services)\n- **Team Experience**: Low (first cloud migration)\n- **Timeline**: Aggressive (9 months for full migration)\n\n**Recommendation**: \n- Extend timeline to 12 months\n- Hire AWS migration partner\n- Increase contingency budget to $300K (from $150K)\n- Conduct phased migration (pilot first, then waves)\n\n---\n\n## Critical Risks\n\n### R-001: Extended Downtime During Cutover\n**Score**: 16 (Probability: 4, Impact: 4)\n\n#### Description\nSwitching from on-premise to AWS requires DNS changes, data synchronization, and service cutover. If anything goes wrong, downtime could extend from planned 4 hours to 24+ hours.\n\n#### Impact Analysis\n- **Revenue Loss**: $50K per hour (e-commerce site)\n- **Customer Impact**: 100K daily active users unable to access service\n- **SLA Breach**: 99.9% uptime commitment violated\n- **Reputation**: Social media complaints, negative press\n- **Contractual**: Penalty clauses in enterprise contracts\n\n**Total Impact**: $1.2M (24 hours downtime) + reputation damage\n\n#### Root Causes\n- Untested cutover procedures\n- Unexpected DNS propagation delays\n- Database replication lag\n- Application configuration errors\n- Network routing issues\n\n#### Mitigation Strategy\n\n**Reduce Probability**:\n\n1. **Rehearse Cutover (5 times)**\n   - Full dress rehearsal in staging\n   - Time every step\n   - Document exact commands\n   - Practice rollback procedure\n   - Schedule: Monthly rehearsals Mar-Jul\n\n2. **Automate Cutover**\n   - Infrastructure as Code (Terraform)\n   - Automated health checks\n   - One-click rollback script\n   - Chaos engineering tests\n\n3. **Minimize Cutover Window**\n   - Pre-sync data (99% before cutover)\n   - Use database replication (MySQL binlog)\n   - Final sync only 1% delta (minutes not hours)\n   - Blue-green deployment where possible\n\n4. **Choose Optimal Timing**\n   - Sunday 2 AM - 6 AM (lowest traffic)\n   - Avoid holiday weekends\n   - Not during quarter-end\n\n**Reduce Impact**:\n\n1. **Graceful Degradation**\n   - Read-only mode if issues arise\n   - Cached content for public pages\n   - Status page communicating progress\n\n2. **Rapid Rollback**\n   - Tested rollback procedure (<30 minutes)\n   - Keep on-premise live for 30 days\n   - DNS TTL set to 60 seconds pre-cutover\n\n3. **Communication Plan**\n   - Pre-announce maintenance window\n   - Hourly updates during cutover\n   - Executive escalation tree\n\n#### Contingency Plan\n\n**Trigger**: Cutover exceeds 6 hours or critical errors\n\n**Action**:\n1. **Hour 0-2**: Normal cutover\n2. **Hour 2-4**: Troubleshoot (war room activated)\n3. **Hour 4-6**: Escalate to AWS support (Premium support)\n4. **Hour 6**: ROLLBACK decision point\n5. **Hour 6-7**: Execute rollback to on-premise\n6. **Hour 7-8**: Verify on-premise stability\n\n**Rollback Procedure**:\n```bash\n# 1. Revert DNS to on-premise IPs\nterraform apply -var=\"dns_target=on-premise\"\n\n# 2. Stop AWS application servers\nkubectl scale deployment --replicas=0 --all\n\n# 3. Sync any new data back to on-premise (if applicable)\n./scripts/reverse-sync.sh\n\n# 4. Verify on-premise health\n./scripts/health-check.sh\n\n# 5. Communicate to customers\n./scripts/send-notification.sh \"Services restored\"\n```\n\n**Decision Maker**: CTO (on-call during cutover)\n\n#### Early Warning Indicators\n- Rehearsal taking longer than 4 hours\n- Data sync taking longer than estimated\n- Application errors in staging cutover\n- Team not confident in procedures\n\n#### Current Status\n- â³ Rehearsals not started (should start Week 3)\n- ğŸ”„ Automation scripts 30% complete\n- âŒ Rollback procedure not documented\n- âŒ Blue-green setup not implemented\n\n**Action Required**: Escalate. This is highest priority risk.\n\n---\n\n### R-002: Data Loss or Corruption During Migration\n**Score**: 16 (Probability: 4, Impact: 4)\n\n#### Description\n50TB of customer data must be migrated. Risk of data corruption, incomplete transfer, or loss during migration.\n\n#### Impact Analysis\n- **Data Loss**: Catastrophic (potential business failure)\n- **Compliance**: GDPR violations if customer data lost\n- **Legal**: Lawsuits from affected customers\n- **Recovery Time**: Weeks to restore from backups (if possible)\n\n**Total Impact**: Potentially existential for company\n\n#### Mitigation Strategy\n\n**Reduce Probability**:\n\n1. **Multiple Validation Layers**\n   ```bash\n   # Checksum validation\n   md5sum source_data > checksums.txt\n   # After migration\n   md5sum migrated_data | diff - checksums.txt\n   \n   # Row count validation\n   SELECT COUNT(*) FROM source_db.table;\n   SELECT COUNT(*) FROM aws_db.table;\n   \n   # Data sampling\n   SELECT * FROM source_db.table ORDER BY RAND() LIMIT 10000;\n   # Compare to AWS\n   ```\n\n2. **Phased Migration**\n   - Wave 1: Non-critical data (10%) - pilot\n   - Wave 2: Development/staging data (20%)\n   - Wave 3: Historical/archived data (30%)\n   - Wave 4: Production data (40%) - most critical\n   - Validate each wave before next\n\n3. **Parallel Running**\n   - Dual-write to both on-premise and AWS\n   - Compare data consistency\n   - Run for 30 days before cutover\n\n**Reduce Impact**:\n\n1. **Comprehensive Backups**\n   - Full backup before migration\n   - Incremental backups during migration\n   - Test restore procedures\n   - Store backups in 3 locations (3-2-1 rule)\n\n2. **Keep Source Data**\n   - Don't delete on-premise data for 90 days\n   - Archive to cold storage after validation\n\n#### Contingency Plan\n\n**Trigger**: Data validation fails (checksum mismatch, row count difference)\n\n**Action**:\n1. HALT migration immediately\n2. Identify scope of data issue\n3. Re-migrate affected data\n4. Triple-check validation\n5. If unfixable, restore from backup\n\n**Recovery Time Objective (RTO)**: 24 hours\n**Recovery Point Objective (RPO)**: Zero data loss acceptable\n\n---\n\n### R-003: Cost Overruns (\"Cloud Bill Shock\")\n**Score**: 12 (Probability: 4, Impact: 3)\n\n#### Description\nAWS costs are complex and unpredictable. Risk of spending 2-3x budget due to:\n- Over-provisioning resources\n- Data transfer costs\n- Unoptimized architecture\n- Forgotten resources (dev/test environments)\n\n#### Impact Analysis\n- **Budget Impact**: $1.2M project â†’ $2.4M actual\n- **Ongoing Costs**: $50K/month estimate â†’ $150K/month actual\n- **Business Case**: ROI turns negative\n\n#### Mitigation Strategy\n\n**Reduce Probability**:\n\n1. **Cost Modeling**\n   - Use AWS Pricing Calculator\n   - Model each service (EC2, RDS, S3, etc.)\n   - Include data transfer costs\n   - Add 30% buffer\n\n2. **Right-Sizing**\n   - Start small, scale up (not vice versa)\n   - Use monitoring to determine actual needs\n   - Reserved Instances for predictable workloads\n   - Spot Instances for batch jobs\n\n3. **Cost Monitoring**\n   - AWS Cost Explorer dashboards\n   - Budget alerts ($50K/month threshold)\n   - Tag all resources by project/team\n   - Weekly cost review meetings\n\n4. **FinOps Practices**\n   - Shutdown dev/test outside business hours\n   - Delete unused EBS volumes\n   - Lifecycle policies for S3 (move to Glacier)\n   - CloudWatch Logs retention (30 days, not forever)\n\n**Reduce Impact**:\n\n1. **Spending Limits**\n   - Hard limit at $75K/month (AWS Budget Actions)\n   - Alert at $50K, $60K, $70K\n\n2. **Architecture Review**\n   - AWS Well-Architected Review\n   - Cost optimization recommendations\n\n#### Contingency Plan\n\n**Trigger**: Monthly costs exceed $60K (20% over budget)\n\n**Action**:\n1. Immediate audit of all resources\n2. Shut down non-essential environments\n3. Right-size over-provisioned instances\n4. Emergency architecture review\n\n**Current Status**:\n- âœ… Cost modeling complete ($45K/month estimate)\n- ğŸ”„ Tagging strategy 60% implemented\n- â³ Budget alerts not set up yet\n- âŒ FinOps practices not defined\n\n---\n\n### R-004: Performance Degradation Post-Migration\n**Score**: 12 (Probability: 3, Impact: 4)\n\n#### Description\nApplications may perform worse on AWS than on-premise due to:\n- Network latency (on-premise apps calling AWS)\n- Database I/O differences\n- Application not optimized for cloud\n\n#### Mitigation Strategy\n\n1. **Performance Baseline**\n   - Measure on-premise performance (APM tool)\n   - Set target SLAs (e.g., API response <200ms)\n   - Load test on AWS before migration\n\n2. **Optimize for Cloud**\n   - Refactor chatty applications\n   - Implement caching (ElastiCache)\n   - Use CDN for static assets\n   - Database query optimization\n\n3. **Hybrid Period**\n   - Keep latency-sensitive apps on-premise initially\n   - Use AWS Direct Connect (not public internet)\n   - Migrate in logical groups (reduce cross-network calls)\n\n#### Contingency Plan\n\nIf performance degrades >20%:\n1. Rollback that component to on-premise\n2. Optimize and re-migrate later\n3. Upgrade AWS instance types\n4. Implement caching layer\n\n---\n\n### R-005: Security Breach During Transition\n**Score**: 12 (Probability: 4, Impact: 3)\n\n#### Description\nMigration creates security gaps:\n- Temporary open firewall rules\n- Data in transit vulnerable\n- Misconfigured AWS security groups\n- IAM permissions too broad initially\n\n#### Mitigation Strategy\n\n1. **Encrypted Transit**\n   - VPN for data migration\n   - TLS for all application traffic\n   - AWS DataSync (encrypted)\n\n2. **Least Privilege**\n   - IAM roles with minimal permissions\n   - MFA for all admin access\n   - Audit IAM policies weekly\n\n3. **Security Scanning**\n   - AWS GuardDuty (threat detection)\n   - AWS Config (compliance monitoring)\n   - Third-party vulnerability scanning\n\n4. **Network Segmentation**\n   - VPC with private subnets\n   - Security groups (not 0.0.0.0/0)\n   - WAF for web applications\n\n#### Contingency Plan\n\n**Trigger**: Security alert or breach detected\n\n**Action**:\n1. Isolate affected resources\n2. Activate incident response team\n3. Forensic analysis\n4. Notify customers if data exposed (GDPR requirement)\n\n---\n\n## Risk Management Plan\n\n### Phase 1: Planning (Months 1-2)\n- Complete risk assessment\n- Finalize mitigation strategies\n- Allocate contingency budget\n- Hire AWS migration partner\n\n### Phase 2: Pilot (Month 3)\n- Migrate non-critical workload (Dev environment)\n- Validate migration procedures\n- Measure performance and costs\n- Refine approach based on learnings\n\n### Phase 3: Waves (Months 4-8)\n- Wave 1: Internal tools (low risk)\n- Wave 2: Customer-facing services (high risk)\n- Wave 3: Databases (highest risk)\n- Wave 4: Legacy applications (medium risk)\n\n### Phase 4: Cutover & Stabilization (Month 9)\n- Final cutover\n- Hypercare period (24/7 support)\n- Performance tuning\n- Decommission on-premise (Month 10)\n\n---\n\n## Risk Budget\n\n| Risk Category | Mitigation Cost | Contingency | Total |\n|---------------|-----------------|-------------|-------|\n| Downtime prevention | $100K | $50K | $150K |\n| Data migration | $75K | $100K | $175K |\n| Security | $50K | $25K | $75K |\n| Performance testing | $40K | $20K | $60K |\n| External consultants | $150K | $50K | $200K |\n| **Total** | **$415K** | **$245K** | **$660K** |\n\n**% of Project Budget**: 55% (high but justified for risk mitigation)\n\n---\n\n## Decision Gates\n\nBefore proceeding to next phase, must meet criteria:\n\n### Gate 1: Proceed to Pilot (End of Month 2)\n- [ ] All critical risks have mitigation plans\n- [ ] AWS architecture reviewed by expert\n- [ ] Team trained on AWS\n- [ ] Budget approved\n\n### Gate 2: Proceed to Wave 1 (End of Month 3)\n- [ ] Pilot migration successful\n- [ ] Performance meets SLAs\n- [ ] Costs within 10% of estimate\n- [ ] Zero data loss in pilot\n\n### Gate 3: Proceed to Production Waves (Month 4)\n- [ ] Cutover procedure tested 3 times\n- [ ] Rollback procedure tested\n- [ ] Incident response team trained\n- [ ] Customer communication ready\n\n### Gate 4: Final Cutover (Month 9)\n- [ ] All waves completed successfully\n- [ ] Performance validated\n- [ ] Security audit passed\n- [ ] Backup and DR tested\n\n**Authority**: CTO must sign off on each gate\n\n---\n\n## Success Criteria\n\n- **Downtime**: <4 hours total\n- **Data Loss**: Zero\n- **Performance**: Within 10% of on-premise\n- **Budget**: Within 20% of $1.2M\n- **Timeline**: Complete by November 30, 2024\n- **Security**: Zero breaches\n\n---\n\n## Weekly Risk Review\n\n**When**: Every Friday 2 PM\n**Who**: Project Manager, Tech Lead, CTO\n**Agenda**:\n1. New risks identified (5 min)\n2. Risk score changes (5 min)\n3. Mitigation progress (10 min)\n4. Blockers and escalations (5 min)\n5. Next week priorities (5 min)\n\n**Output**: Updated risk register, action items\n```\n\n---\n\n## Best Practices\n\n### Risk Identification\n\n1. **Use Multiple Techniques**\n   - Brainstorming sessions\n   - Pre-mortem (\"imagine it failed\")\n   - Lessons learned from past projects\n   - Expert interviews\n   - Checklists (technical, organizational, external)\n\n2. **Think Broadly**\n   - Technical risks (bugs, performance)\n   - Organizational risks (staffing, skills)\n   - External risks (vendors, market, regulations)\n   - Business risks (competition, budget)\n\n3. **Be Specific**\n   - Not: \"Something might go wrong\"\n   - Better: \"Database migration script might corrupt data due to character encoding issues\"\n\n### Risk Analysis\n\n1. **Use Data When Possible**\n   - Historical failure rates\n   - Industry benchmarks\n   - Expert estimates\n\n2. **Consider Correlation**\n   - Some risks are linked (key person leaves â†’ knowledge loss â†’ delays)\n   - Cascade effects\n\n3. **Update Regularly**\n   - Risks change over time\n   - New information emerges\n   - Mitigation reduces probability/impact\n\n### Risk Mitigation\n\n1. **Focus on High-Impact Risks**\n   - Not all risks deserve equal attention\n   - Prioritize ruthlessly\n   - Accept low-priority risks\n\n2. **Multiple Layers**\n   - Reduce probability AND impact\n   - Have contingency plans\n   - Monitor early warning indicators\n\n3. **Assign Owners**\n   - Every risk needs an owner\n   - Owner is responsible for monitoring and mitigation\n   - Not the PM's job alone\n\n### Common Pitfalls\n\n- **Ignoring risks**: Hoping they go away\n- **Analysis paralysis**: Over-analyzing, not acting\n- **One-time assessment**: Not updating as project evolves\n- **No ownership**: \"Somebody should handle this\"\n- **Insufficient mitigation**: Band-aids on critical risks\n- **No contingency plans**: \"We'll figure it out if it happens\"\n\n## Templates\n\n### Risk Register Template\n\n```markdown\n| ID | Risk | Category | Probability | Impact | Score | Owner | Status | Mitigation |\n|----|------|----------|-------------|--------|-------|-------|--------|------------|\n| R-001 | [Description] | Technical | 3 | 4 | 12 | Name | Open | [Strategy] |\n```\n\n### Pre-Mortem Template\n\n\"It's [END DATE]. The project has failed. Working backward, what went wrong?\"\n\n1. [Failure scenario 1]\n2. [Failure scenario 2]\n3. ...\n\nConvert each to a risk in the register.\n\n### Contingency Plan Template\n\n```markdown\n## Contingency Plan for [Risk]\n\n**Trigger**: [What indicates this risk is happening]\n\n**Response**:\n1. [Immediate action]\n2. [Secondary action]\n3. [Escalation if needed]\n\n**Decision Maker**: [Role]\n**Budget**: [Allocated contingency]\n**Timeline**: [How long to execute plan]\n```\n",
  "prompt": "A skill that conducts thorough risk analysis, develops mitigation strategies, and creates contingency plans for projects. Uses industry-standard frameworks including RAID logs, risk matrices, pre-mortem analysis, and failure mode analysis. Generates comprehensive risk registers with detailed mitigation plans, early warning indicators, and contingency strategies. Perfect for project managers, engineering leads, and teams managing complex, high-stakes initiatives.",
  "createdAt": "2024-01-15T10:00:00.000Z",
  "published": true
}
