{
  "id": "premade-etl",
  "name": "etl-pipeline",
  "description": "Build ETL data pipelines",
  "category": "Data",
  "content": "---\nname: etl-pipeline\ndescription: When the user needs data extraction, transformation, or loading\ncategory: Data\n---\n\n# ETL Pipeline\n\n## Overview\nBuild Extract, Transform, Load pipelines for data processing.\n\n## Activation\nActivates when user mentions \"ETL\", \"data pipeline\", \"data import\", \"data transformation\", or \"batch processing\".\n\n## Instructions\n\n1. Extract: Identify data sources\n2. Transform: Clean, validate, reshape\n3. Load: Write to destination\n4. Add error handling and logging\n\n## Examples\n\n**CSV to Database Pipeline:**\n```javascript\nimport { createReadStream } from 'fs';\nimport { parse } from 'csv-parse';\nimport { Transform } from 'stream';\n\nasync function runETL(filePath) {\n  const stats = { processed: 0, errors: 0 };\n\n  // Extract\n  const parser = createReadStream(filePath)\n    .pipe(parse({ columns: true, skip_empty_lines: true }));\n\n  // Transform\n  const transformer = new Transform({\n    objectMode: true,\n    transform(row, enc, callback) {\n      try {\n        const transformed = {\n          email: row.email?.toLowerCase().trim(),\n          name: row.name?.trim(),\n          amount: parseFloat(row.amount) || 0,\n          date: new Date(row.date),\n          isValid: Boolean(row.email && row.amount > 0)\n        };\n        \n        if (transformed.isValid) {\n          this.push(transformed);\n        }\n        stats.processed++;\n        callback();\n      } catch (err) {\n        stats.errors++;\n        callback();\n      }\n    }\n  });\n\n  // Load (batch insert)\n  const batch = [];\n  const BATCH_SIZE = 1000;\n\n  for await (const record of parser.pipe(transformer)) {\n    batch.push(record);\n    if (batch.length >= BATCH_SIZE) {\n      await db.records.insertMany(batch);\n      batch.length = 0;\n    }\n  }\n\n  if (batch.length > 0) {\n    await db.records.insertMany(batch);\n  }\n\n  return stats;\n}\n```",
  "prompt": "A skill that builds ETL data pipelines",
  "createdAt": "2024-01-15T10:00:00.000Z",
  "published": true
}
