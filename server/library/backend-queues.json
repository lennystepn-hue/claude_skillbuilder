{
  "id": "backend-queues",
  "name": "Message Queues & Job Processing",
  "description": "Complete message queue patterns with Bull, BullMQ, RabbitMQ, job processing, scheduling, retries, and distributed task management",
  "category": "Backend",
  "content": "---\nname: Message Queues & Job Processing\ndescription: Complete message queue patterns with Bull, BullMQ, RabbitMQ, job processing, scheduling, retries, and distributed task management\ncategory: Backend\n---\n\n# Message Queues & Job Processing\n\n## Overview\n\nThis skill provides production-ready message queue and job processing patterns using Bull/BullMQ (Redis-based) and RabbitMQ. It covers queue setup, job creation, processing, scheduling, retries, error handling, concurrency, priority queues, and monitoring.\n\n## Activation\n\nUse this skill when:\n- Processing background jobs asynchronously\n- Implementing email sending, file processing, or data imports\n- Building task scheduling systems\n- Handling long-running operations outside request/response cycle\n- Implementing retry logic with exponential backoff\n- Building distributed job processing systems\n- Creating scheduled jobs (cron-like)\n- Implementing priority queues\n- Building event-driven architectures\n\n## Instructions\n\n1. **Choose Queue System**: Select Bull/BullMQ (Redis) or RabbitMQ\n2. **Define Job Types**: Create typed job definitions\n3. **Set up Queue**: Configure queue with connection and options\n4. **Create Producers**: Add jobs to queue from your application\n5. **Create Workers**: Process jobs in separate worker processes\n6. **Handle Errors**: Implement retry logic and dead letter queues\n7. **Add Scheduling**: Set up cron jobs and delayed jobs\n8. **Monitor**: Track job progress, failures, and metrics\n9. **Scale**: Run multiple workers for concurrency\n10. **Optimize**: Use batching, priority, and rate limiting\n\n## Examples\n\n### Bull Queue Setup (Redis-based)\n\n```typescript\n// src/config/queue.config.ts\nimport Queue, { QueueOptions, JobOptions } from 'bull';\nimport { createBullBoard } from '@bull-board/api';\nimport { BullAdapter } from '@bull-board/api/bullAdapter';\nimport { ExpressAdapter } from '@bull-board/express';\n\nconst redisConfig = {\n  host: process.env.REDIS_HOST || 'localhost',\n  port: parseInt(process.env.REDIS_PORT || '6379'),\n  password: process.env.REDIS_PASSWORD,\n};\n\nexport const queueOptions: QueueOptions = {\n  redis: redisConfig,\n  defaultJobOptions: {\n    attempts: 3,\n    backoff: {\n      type: 'exponential',\n      delay: 2000,\n    },\n    removeOnComplete: 100, // Keep last 100 completed jobs\n    removeOnFail: 500, // Keep last 500 failed jobs\n  },\n};\n\n// Create queues\nexport const emailQueue = new Queue('email', queueOptions);\nexport const imageQueue = new Queue('image-processing', queueOptions);\nexport const reportQueue = new Queue('report-generation', queueOptions);\nexport const notificationQueue = new Queue('notifications', queueOptions);\n\n// Bull Board for monitoring\nconst serverAdapter = new ExpressAdapter();\nserverAdapter.setBasePath('/admin/queues');\n\ncreateBullBoard({\n  queues: [\n    new BullAdapter(emailQueue),\n    new BullAdapter(imageQueue),\n    new BullAdapter(reportQueue),\n    new BullAdapter(notificationQueue),\n  ],\n  serverAdapter,\n});\n\nexport const bullBoardRouter = serverAdapter.getRouter();\n\n// src/types/jobs.types.ts\nexport interface EmailJobData {\n  to: string;\n  subject: string;\n  template: string;\n  data: Record<string, any>;\n  attachments?: Array<{\n    filename: string;\n    path: string;\n  }>;\n}\n\nexport interface ImageProcessingJobData {\n  imageUrl: string;\n  userId: string;\n  operations: Array<{\n    type: 'resize' | 'crop' | 'compress' | 'watermark';\n    params: Record<string, any>;\n  }>;\n}\n\nexport interface ReportJobData {\n  userId: string;\n  reportType: 'sales' | 'analytics' | 'inventory';\n  dateRange: {\n    start: Date;\n    end: Date;\n  };\n  format: 'pdf' | 'csv' | 'excel';\n}\n\nexport interface NotificationJobData {\n  userId: string;\n  type: 'push' | 'sms' | 'in-app';\n  title: string;\n  message: string;\n  data?: Record<string, any>;\n}\n\n// src/queues/email.queue.ts\nimport { emailQueue } from '../config/queue.config';\nimport { EmailJobData } from '../types/jobs.types';\nimport { Job, JobOptions } from 'bull';\nimport nodemailer from 'nodemailer';\nimport { renderTemplate } from '../utils/template.util';\n\n// Email transporter\nconst transporter = nodemailer.createTransport({\n  host: process.env.SMTP_HOST,\n  port: parseInt(process.env.SMTP_PORT || '587'),\n  secure: false,\n  auth: {\n    user: process.env.SMTP_USER,\n    pass: process.env.SMTP_PASS,\n  },\n});\n\nexport class EmailQueueProducer {\n  // Add email job to queue\n  static async sendEmail(\n    data: EmailJobData,\n    options: JobOptions = {}\n  ): Promise<Job<EmailJobData>> {\n    return emailQueue.add('send-email', data, {\n      priority: options.priority || 1,\n      delay: options.delay,\n      attempts: options.attempts || 3,\n      ...options,\n    });\n  }\n\n  // Send bulk emails\n  static async sendBulkEmails(\n    emails: EmailJobData[],\n    options: JobOptions = {}\n  ): Promise<Job<EmailJobData>[]> {\n    const jobs = emails.map(email =>\n      emailQueue.add('send-email', email, {\n        priority: 2, // Lower priority for bulk\n        ...options,\n      })\n    );\n    return Promise.all(jobs);\n  }\n\n  // Schedule email for later\n  static async scheduleEmail(\n    data: EmailJobData,\n    sendAt: Date\n  ): Promise<Job<EmailJobData>> {\n    const delay = sendAt.getTime() - Date.now();\n    return this.sendEmail(data, { delay: Math.max(0, delay) });\n  }\n}\n\nexport class EmailQueueWorker {\n  // Process email jobs\n  static async processJobs(concurrency = 5): Promise<void> {\n    emailQueue.process('send-email', concurrency, async (job: Job<EmailJobData>) => {\n      const { to, subject, template, data, attachments } = job.data;\n\n      try {\n        // Update progress\n        await job.progress(10);\n\n        // Render email template\n        const html = await renderTemplate(template, data);\n        await job.progress(30);\n\n        // Send email\n        const result = await transporter.sendMail({\n          from: process.env.SMTP_FROM || 'noreply@example.com',\n          to,\n          subject,\n          html,\n          attachments,\n        });\n\n        await job.progress(100);\n\n        return {\n          messageId: result.messageId,\n          accepted: result.accepted,\n        };\n      } catch (error) {\n        console.error('Email send failed:', error);\n        throw error; // Will trigger retry\n      }\n    });\n\n    // Event handlers\n    emailQueue.on('completed', (job, result) => {\n      console.log(`Email job ${job.id} completed:`, result);\n    });\n\n    emailQueue.on('failed', (job, err) => {\n      console.error(`Email job ${job?.id} failed:`, err.message);\n    });\n\n    emailQueue.on('stalled', (job) => {\n      console.warn(`Email job ${job.id} stalled`);\n    });\n  }\n}\n\n// src/queues/image-processing.queue.ts\nimport { imageQueue } from '../config/queue.config';\nimport { ImageProcessingJobData } from '../types/jobs.types';\nimport { Job } from 'bull';\nimport sharp from 'sharp';\nimport axios from 'axios';\nimport { S3Client, PutObjectCommand } from '@aws-sdk/client-s3';\n\nconst s3Client = new S3Client({ region: process.env.AWS_REGION });\n\nexport class ImageQueueProducer {\n  static async processImage(\n    data: ImageProcessingJobData\n  ): Promise<Job<ImageProcessingJobData>> {\n    return imageQueue.add('process-image', data, {\n      priority: 1,\n      attempts: 3,\n      timeout: 60000, // 1 minute timeout\n    });\n  }\n}\n\nexport class ImageQueueWorker {\n  static async processJobs(concurrency = 3): Promise<void> {\n    imageQueue.process('process-image', concurrency, async (job: Job<ImageProcessingJobData>) => {\n      const { imageUrl, userId, operations } = job.data;\n\n      try {\n        await job.progress(10);\n\n        // Download image\n        const response = await axios.get(imageUrl, { responseType: 'arraybuffer' });\n        let imageBuffer = Buffer.from(response.data);\n\n        await job.progress(30);\n\n        // Apply operations\n        let pipeline = sharp(imageBuffer);\n\n        for (const [index, operation] of operations.entries()) {\n          switch (operation.type) {\n            case 'resize':\n              pipeline = pipeline.resize(operation.params.width, operation.params.height);\n              break;\n            case 'crop':\n              pipeline = pipeline.extract(operation.params);\n              break;\n            case 'compress':\n              pipeline = pipeline.jpeg({ quality: operation.params.quality || 80 });\n              break;\n            case 'watermark':\n              const watermark = await sharp(operation.params.watermarkPath)\n                .resize(operation.params.width)\n                .toBuffer();\n              pipeline = pipeline.composite([{ input: watermark, gravity: 'southeast' }]);\n              break;\n          }\n\n          await job.progress(30 + (index + 1) * (40 / operations.length));\n        }\n\n        // Process image\n        const processedBuffer = await pipeline.toBuffer();\n\n        await job.progress(80);\n\n        // Upload to S3\n        const key = `processed/${userId}/${Date.now()}.jpg`;\n        await s3Client.send(\n          new PutObjectCommand({\n            Bucket: process.env.S3_BUCKET,\n            Key: key,\n            Body: processedBuffer,\n            ContentType: 'image/jpeg',\n          })\n        );\n\n        await job.progress(100);\n\n        return {\n          url: `https://${process.env.S3_BUCKET}.s3.amazonaws.com/${key}`,\n          size: processedBuffer.length,\n        };\n      } catch (error) {\n        console.error('Image processing failed:', error);\n        throw error;\n      }\n    });\n\n    imageQueue.on('completed', (job, result) => {\n      console.log(`Image processing job ${job.id} completed:`, result);\n    });\n\n    imageQueue.on('failed', (job, err) => {\n      console.error(`Image processing job ${job?.id} failed:`, err.message);\n    });\n  }\n}\n\n// src/queues/scheduled-jobs.ts\nimport { Queue } from 'bull';\nimport { queueOptions } from '../config/queue.config';\n\nconst scheduledQueue = new Queue('scheduled-jobs', queueOptions);\n\nexport class ScheduledJobs {\n  // Clean up old data every day at 2 AM\n  static async setupDailyCleanup(): Promise<void> {\n    await scheduledQueue.add(\n      'cleanup-old-data',\n      {},\n      {\n        repeat: {\n          cron: '0 2 * * *', // 2 AM daily\n        },\n      }\n    );\n  }\n\n  // Send weekly reports every Monday at 9 AM\n  static async setupWeeklyReports(): Promise<void> {\n    await scheduledQueue.add(\n      'weekly-reports',\n      {},\n      {\n        repeat: {\n          cron: '0 9 * * 1', // Monday 9 AM\n        },\n      }\n    );\n  }\n\n  // Backup database every 6 hours\n  static async setupDatabaseBackup(): Promise<void> {\n    await scheduledQueue.add(\n      'database-backup',\n      {},\n      {\n        repeat: {\n          every: 6 * 60 * 60 * 1000, // 6 hours in milliseconds\n        },\n      }\n    );\n  }\n\n  // Process scheduled jobs\n  static async processJobs(): Promise<void> {\n    scheduledQueue.process('cleanup-old-data', async (job) => {\n      console.log('Running daily cleanup...');\n      // Cleanup logic here\n      return { cleaned: 100 };\n    });\n\n    scheduledQueue.process('weekly-reports', async (job) => {\n      console.log('Generating weekly reports...');\n      // Report generation logic\n      return { reportsSent: 50 };\n    });\n\n    scheduledQueue.process('database-backup', async (job) => {\n      console.log('Backing up database...');\n      // Backup logic\n      return { success: true };\n    });\n  }\n}\n\n// src/workers/worker.ts\nimport { EmailQueueWorker } from '../queues/email.queue';\nimport { ImageQueueWorker } from '../queues/image-processing.queue';\nimport { ScheduledJobs } from '../queues/scheduled-jobs';\n\nasync function startWorker() {\n  console.log('Starting worker...');\n\n  try {\n    // Start processing jobs\n    await EmailQueueWorker.processJobs(5);\n    await ImageQueueWorker.processJobs(3);\n    await ScheduledJobs.processJobs();\n\n    // Setup scheduled jobs\n    await ScheduledJobs.setupDailyCleanup();\n    await ScheduledJobs.setupWeeklyReports();\n    await ScheduledJobs.setupDatabaseBackup();\n\n    console.log('Worker started successfully');\n  } catch (error) {\n    console.error('Worker error:', error);\n    process.exit(1);\n  }\n}\n\n// Graceful shutdown\nprocess.on('SIGTERM', async () => {\n  console.log('SIGTERM received, closing worker...');\n  process.exit(0);\n});\n\nstartWorker();\n```\n\n### RabbitMQ Setup\n\n```typescript\n// src/config/rabbitmq.config.ts\nimport amqp, { Connection, Channel } from 'amqplib';\n\nexport class RabbitMQConnection {\n  private static connection: Connection | null = null;\n  private static channel: Channel | null = null;\n\n  static async connect(): Promise<void> {\n    try {\n      const url = process.env.RABBITMQ_URL || 'amqp://localhost';\n      this.connection = await amqp.connect(url);\n      this.channel = await this.connection.createChannel();\n\n      console.log('RabbitMQ connected');\n\n      // Handle connection errors\n      this.connection.on('error', (err) => {\n        console.error('RabbitMQ connection error:', err);\n      });\n\n      this.connection.on('close', () => {\n        console.log('RabbitMQ connection closed');\n      });\n    } catch (error) {\n      console.error('Failed to connect to RabbitMQ:', error);\n      throw error;\n    }\n  }\n\n  static async getChannel(): Promise<Channel> {\n    if (!this.channel) {\n      await this.connect();\n    }\n    return this.channel!;\n  }\n\n  static async close(): Promise<void> {\n    await this.channel?.close();\n    await this.connection?.close();\n  }\n}\n\n// src/queues/rabbitmq.email.queue.ts\nimport { RabbitMQConnection } from '../config/rabbitmq.config';\nimport { EmailJobData } from '../types/jobs.types';\n\nconst QUEUE_NAME = 'emails';\nconst EXCHANGE_NAME = 'email-exchange';\nconst DEAD_LETTER_EXCHANGE = 'email-dlx';\nconst DEAD_LETTER_QUEUE = 'emails-failed';\n\nexport class RabbitMQEmailQueue {\n  // Initialize queue and exchange\n  static async initialize(): Promise<void> {\n    const channel = await RabbitMQConnection.getChannel();\n\n    // Create dead letter exchange and queue\n    await channel.assertExchange(DEAD_LETTER_EXCHANGE, 'direct', { durable: true });\n    await channel.assertQueue(DEAD_LETTER_QUEUE, { durable: true });\n    await channel.bindQueue(DEAD_LETTER_QUEUE, DEAD_LETTER_EXCHANGE, 'failed');\n\n    // Create main exchange\n    await channel.assertExchange(EXCHANGE_NAME, 'topic', { durable: true });\n\n    // Create main queue with DLX\n    await channel.assertQueue(QUEUE_NAME, {\n      durable: true,\n      deadLetterExchange: DEAD_LETTER_EXCHANGE,\n      deadLetterRoutingKey: 'failed',\n      messageTtl: 3600000, // 1 hour\n    });\n\n    // Bind queue to exchange\n    await channel.bindQueue(QUEUE_NAME, EXCHANGE_NAME, 'email.#');\n  }\n\n  // Publish email job\n  static async sendEmail(data: EmailJobData, priority = 1): Promise<boolean> {\n    const channel = await RabbitMQConnection.getChannel();\n\n    const message = JSON.stringify(data);\n\n    return channel.publish(EXCHANGE_NAME, 'email.send', Buffer.from(message), {\n      persistent: true,\n      priority,\n      contentType: 'application/json',\n      timestamp: Date.now(),\n    });\n  }\n\n  // Consume email jobs\n  static async consumeEmails(concurrency = 5): Promise<void> {\n    const channel = await RabbitMQConnection.getChannel();\n\n    // Set prefetch count for concurrency control\n    await channel.prefetch(concurrency);\n\n    await channel.consume(\n      QUEUE_NAME,\n      async (msg) => {\n        if (!msg) return;\n\n        try {\n          const data: EmailJobData = JSON.parse(msg.content.toString());\n\n          console.log('Processing email:', data.to);\n\n          // Process email (same logic as Bull example)\n          // ...\n\n          // Acknowledge message\n          channel.ack(msg);\n        } catch (error) {\n          console.error('Email processing failed:', error);\n\n          // Retry logic\n          const retryCount = (msg.properties.headers?.['x-retry-count'] || 0) + 1;\n\n          if (retryCount < 3) {\n            // Requeue with delay\n            setTimeout(() => {\n              channel.publish(\n                EXCHANGE_NAME,\n                'email.send',\n                msg.content,\n                {\n                  ...msg.properties,\n                  headers: {\n                    ...msg.properties.headers,\n                    'x-retry-count': retryCount,\n                  },\n                }\n              );\n              channel.ack(msg);\n            }, retryCount * 5000); // Exponential backoff\n          } else {\n            // Max retries exceeded, send to DLQ\n            channel.nack(msg, false, false);\n          }\n        }\n      },\n      { noAck: false }\n    );\n  }\n}\n\n// src/queues/priority.queue.ts\nimport { Queue, Job } from 'bull';\nimport { queueOptions } from '../config/queue.config';\n\nconst priorityQueue = new Queue('priority-tasks', {\n  ...queueOptions,\n  defaultJobOptions: {\n    ...queueOptions.defaultJobOptions,\n    removeOnComplete: true,\n  },\n});\n\nexport enum TaskPriority {\n  CRITICAL = 1,\n  HIGH = 2,\n  NORMAL = 3,\n  LOW = 4,\n}\n\nexport class PriorityQueueManager {\n  // Add task with priority\n  static async addTask(\n    type: string,\n    data: any,\n    priority: TaskPriority = TaskPriority.NORMAL\n  ): Promise<Job> {\n    return priorityQueue.add(type, data, {\n      priority,\n      attempts: priority === TaskPriority.CRITICAL ? 5 : 3,\n    });\n  }\n\n  // Process tasks\n  static async processTasks(): Promise<void> {\n    priorityQueue.process('*', 10, async (job) => {\n      console.log(`Processing ${job.name} with priority ${job.opts.priority}`);\n      \n      // Task processing logic based on job.name\n      switch (job.name) {\n        case 'send-notification':\n          // Handle notification\n          break;\n        case 'process-payment':\n          // Handle payment\n          break;\n        default:\n          console.warn('Unknown job type:', job.name);\n      }\n\n      return { success: true };\n    });\n  }\n}\n\n// src/utils/queue.monitor.ts\nimport { Queue } from 'bull';\n\nexport class QueueMonitor {\n  static async getQueueStats(queue: Queue) {\n    const [waiting, active, completed, failed, delayed] = await Promise.all([\n      queue.getWaitingCount(),\n      queue.getActiveCount(),\n      queue.getCompletedCount(),\n      queue.getFailedCount(),\n      queue.getDelayedCount(),\n    ]);\n\n    return {\n      waiting,\n      active,\n      completed,\n      failed,\n      delayed,\n      total: waiting + active + completed + failed + delayed,\n    };\n  }\n\n  static async cleanOldJobs(queue: Queue, olderThan = 7 * 24 * 60 * 60 * 1000): Promise<void> {\n    await queue.clean(olderThan, 'completed');\n    await queue.clean(olderThan, 'failed');\n  }\n\n  static async retryFailedJobs(queue: Queue): Promise<void> {\n    const failed = await queue.getFailed();\n    \n    for (const job of failed) {\n      await job.retry();\n    }\n  }\n}\n```\n\n## Best Practices\n\n1. **Use separate worker processes**: Don't process jobs in web server\n2. **Set appropriate timeouts**: Prevent jobs from hanging indefinitely\n3. **Implement retry logic**: Use exponential backoff\n4. **Monitor queue health**: Track waiting, active, and failed jobs\n5. **Use dead letter queues**: Capture permanently failed jobs\n6. **Set job priorities**: Critical jobs should process first\n7. **Limit concurrency**: Don't overwhelm external services\n8. **Clean up old jobs**: Remove completed/failed jobs regularly\n9. **Use job progress**: Track long-running job progress\n10. **Handle graceful shutdown**: Wait for active jobs to complete",
  "prompt": "A skill that provides complete message queue and job processing patterns with Bull, BullMQ, and RabbitMQ, including job scheduling, retries, distributed processing, and monitoring with production-ready best practices",
  "createdAt": "2024-01-15T10:00:00.000Z",
  "published": true
}
