{
  "id": "ai-embeddings",
  "name": "embeddings-search",
  "description": "Implement semantic search with vector embeddings",
  "category": "AI",
  "content": "---\nname: embeddings-search\ndescription: Semantic search with embeddings\ncategory: AI\n---\n\n# Embeddings & Semantic Search\n\n## Overview\nImplement semantic search using vector embeddings for similarity matching, recommendations, and retrieval.\n\n## Activation\nActivates when user mentions \"embeddings\", \"semantic search\", \"vector search\", \"similarity\", \"cosine similarity\", or \"nearest neighbors\".\n\n## Instructions\n\n### Embedding Models\n- **OpenAI**: text-embedding-3-small/large (best quality)\n- **Sentence Transformers**: all-MiniLM-L6-v2 (free, fast)\n- **Cohere**: embed-english-v3.0 (multilingual)\n- **Voyage AI**: voyage-large-2 (code-optimized available)\n\n### Vector Databases\n- **Pinecone**: Managed, scalable\n- **Chroma**: Local, easy setup\n- **Weaviate**: Hybrid search\n- **Qdrant**: High performance\n- **pgvector**: PostgreSQL extension\n\n## Examples\n\n**Complete Semantic Search System:**\n```python\nimport numpy as np\nfrom openai import OpenAI\nfrom typing import List, Tuple\nimport json\n\nclass SemanticSearch:\n    def __init__(self, model=\"text-embedding-3-small\"):\n        self.client = OpenAI()\n        self.model = model\n        self.documents = []\n        self.embeddings = []\n    \n    def embed(self, texts: List[str]) -> np.ndarray:\n        \"\"\"Generate embeddings for texts.\"\"\"\n        response = self.client.embeddings.create(\n            model=self.model,\n            input=texts\n        )\n        return np.array([e.embedding for e in response.data])\n    \n    def index(self, documents: List[dict]):\n        \"\"\"Index documents with their embeddings.\"\"\"\n        self.documents = documents\n        texts = [d.get('text', d.get('content', str(d))) for d in documents]\n        self.embeddings = self.embed(texts)\n        print(f\"Indexed {len(documents)} documents\")\n    \n    def search(self, query: str, top_k: int = 5) -> List[Tuple[dict, float]]:\n        \"\"\"Search for similar documents.\"\"\"\n        query_embedding = self.embed([query])[0]\n        \n        # Cosine similarity\n        similarities = np.dot(self.embeddings, query_embedding) / (\n            np.linalg.norm(self.embeddings, axis=1) * np.linalg.norm(query_embedding)\n        )\n        \n        # Get top-k indices\n        top_indices = np.argsort(similarities)[-top_k:][::-1]\n        \n        return [(self.documents[i], float(similarities[i])) for i in top_indices]\n    \n    def save(self, path: str):\n        \"\"\"Save index to disk.\"\"\"\n        data = {\n            'documents': self.documents,\n            'embeddings': self.embeddings.tolist()\n        }\n        with open(path, 'w') as f:\n            json.dump(data, f)\n    \n    def load(self, path: str):\n        \"\"\"Load index from disk.\"\"\"\n        with open(path, 'r') as f:\n            data = json.load(f)\n        self.documents = data['documents']\n        self.embeddings = np.array(data['embeddings'])\n\n# Usage\nsearch = SemanticSearch()\nsearch.index([\n    {\"id\": 1, \"text\": \"Python is great for machine learning\"},\n    {\"id\": 2, \"text\": \"JavaScript powers the modern web\"},\n    {\"id\": 3, \"text\": \"Neural networks learn patterns from data\"},\n])\n\nresults = search.search(\"AI and deep learning\", top_k=2)\nfor doc, score in results:\n    print(f\"{score:.3f}: {doc['text']}\")\n```\n\n**With Chroma Vector DB:**\n```python\nimport chromadb\nfrom chromadb.utils import embedding_functions\n\nclass ChromaSearch:\n    def __init__(self, collection_name=\"documents\"):\n        self.client = chromadb.PersistentClient(path=\"./chroma_db\")\n        self.embedding_fn = embedding_functions.OpenAIEmbeddingFunction(\n            model_name=\"text-embedding-3-small\"\n        )\n        self.collection = self.client.get_or_create_collection(\n            name=collection_name,\n            embedding_function=self.embedding_fn,\n            metadata={\"hnsw:space\": \"cosine\"}\n        )\n    \n    def add(self, documents: List[str], ids: List[str], metadata: List[dict] = None):\n        \"\"\"Add documents to the collection.\"\"\"\n        self.collection.add(\n            documents=documents,\n            ids=ids,\n            metadatas=metadata or [{} for _ in documents]\n        )\n    \n    def search(self, query: str, n_results: int = 5, where: dict = None):\n        \"\"\"Search for similar documents.\"\"\"\n        results = self.collection.query(\n            query_texts=[query],\n            n_results=n_results,\n            where=where\n        )\n        return list(zip(\n            results['documents'][0],\n            results['distances'][0],\n            results['metadatas'][0]\n        ))\n    \n    def hybrid_search(self, query: str, keyword: str, n_results: int = 5):\n        \"\"\"Combine semantic and keyword search.\"\"\"\n        results = self.collection.query(\n            query_texts=[query],\n            n_results=n_results,\n            where_document={\"$contains\": keyword}\n        )\n        return results\n\n# Usage\ndb = ChromaSearch()\ndb.add(\n    documents=[\"ML tutorial\", \"Web dev guide\", \"AI research paper\"],\n    ids=[\"doc1\", \"doc2\", \"doc3\"],\n    metadata=[{\"type\": \"tutorial\"}, {\"type\": \"guide\"}, {\"type\": \"paper\"}]\n)\nresults = db.search(\"machine learning basics\", n_results=2)\n```",
  "prompt": "A skill for semantic search with embeddings",
  "createdAt": "2024-01-15T10:00:00.000Z",
  "published": true
}
