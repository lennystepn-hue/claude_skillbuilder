{
  "id": "productivity-shell-scripts",
  "name": "Shell Scripts & Automation",
  "description": "Bash/shell scripting for automation, one-liners, and productivity workflows",
  "category": "Productivity",
  "content": "---\nname: Shell Scripts & Automation\ndescription: Bash/shell scripting for automation, one-liners, and productivity workflows\ncategory: Productivity\n---\n\n# Shell Scripts & Automation\n\n## Overview\n\nThis skill provides comprehensive guidance on writing effective shell scripts, powerful one-liners, and automation workflows. It covers bash scripting best practices, common patterns, error handling, and productivity-boosting automation techniques for both Unix/Linux and cross-platform environments.\n\n## Activation\n\nUse this skill when:\n- Writing bash/shell scripts for automation\n- Creating one-liner commands for quick tasks\n- Building CI/CD scripts or deployment workflows\n- Automating repetitive development tasks\n- Processing files, text, or data in bulk\n- Setting up cron jobs or scheduled tasks\n- Creating developer productivity tools\n\n## Instructions\n\n### Script Structure Best Practices\n\n1. **Always use proper shebang and set options**\n   ```bash\n   #!/usr/bin/env bash\n   set -euo pipefail  # Exit on error, undefined vars, pipe failures\n   IFS=$'\\n\\t'        # Safer word splitting\n   ```\n\n2. **Include script metadata and usage**\n   ```bash\n   # Description: Script purpose\n   # Author: Name\n   # Usage: ./script.sh [options] <args>\n   \n   usage() {\n     cat <<EOF\n   Usage: $(basename \"$0\") [OPTIONS] <argument>\n   \n   Description of what this script does.\n   \n   OPTIONS:\n     -h, --help      Show this help message\n     -v, --verbose   Enable verbose output\n     -o, --output    Output file path\n   \n   EXAMPLES:\n     $(basename \"$0\") -v input.txt\n     $(basename \"$0\") --output result.txt data.csv\n   EOF\n   }\n   ```\n\n3. **Implement argument parsing**\n   ```bash\n   VERBOSE=0\n   OUTPUT_FILE=\"\"\n   \n   while [[ $# -gt 0 ]]; do\n     case $1 in\n       -h|--help)\n         usage\n         exit 0\n         ;;\n       -v|--verbose)\n         VERBOSE=1\n         shift\n         ;;\n       -o|--output)\n         OUTPUT_FILE=\"$2\"\n         shift 2\n         ;;\n       -*)\n         echo \"Unknown option: $1\" >&2\n         usage\n         exit 1\n         ;;\n       *)\n         POSITIONAL_ARGS+=(\"$1\")\n         shift\n         ;;\n     esac\n   done\n   ```\n\n4. **Use functions for organization**\n   ```bash\n   # Check if command exists\n   command_exists() {\n     command -v \"$1\" >/dev/null 2>&1\n   }\n   \n   # Logging functions\n   log_info() {\n     echo \"[INFO] $*\" >&2\n   }\n   \n   log_error() {\n     echo \"[ERROR] $*\" >&2\n   }\n   \n   log_debug() {\n     [[ $VERBOSE -eq 1 ]] && echo \"[DEBUG] $*\" >&2\n   }\n   \n   # Cleanup on exit\n   cleanup() {\n     local exit_code=$?\n     log_debug \"Cleaning up temporary files...\"\n     rm -f \"$TEMP_FILE\"\n     exit $exit_code\n   }\n   trap cleanup EXIT INT TERM\n   ```\n\n### Common Automation Patterns\n\n#### File Processing\n```bash\n# Find and process files\nfind . -type f -name \"*.log\" -mtime +30 | while read -r file; do\n  echo \"Archiving: $file\"\n  gzip \"$file\"\ndone\n\n# Parallel processing with xargs\nfind . -name \"*.jpg\" -print0 | xargs -0 -P 4 -I {} convert {} -resize 800x600 {}\n\n# Batch rename files\nfor file in *.txt; do\n  mv \"$file\" \"${file%.txt}_backup.txt\"\ndone\n```\n\n#### Git Automation\n```bash\n# Update all git repos in subdirectories\nfind . -maxdepth 2 -type d -name \".git\" | while read -r gitdir; do\n  repo=$(dirname \"$gitdir\")\n  echo \"Updating: $repo\"\n  (cd \"$repo\" && git pull --rebase)\ndone\n\n# Clean merged branches\ngit branch --merged main | grep -v \"^\\* main$\" | xargs -r git branch -d\n\n# Find large files in git history\ngit rev-list --objects --all | \\\n  git cat-file --batch-check='%(objecttype) %(objectname) %(objectsize) %(rest)' | \\\n  sed -n 's/^blob //p' | \\\n  sort -nk2 | \\\n  tail -20\n```\n\n#### System Monitoring\n```bash\n# Check disk usage and alert\ncheck_disk_usage() {\n  local threshold=80\n  local usage=$(df -h / | awk 'NR==2 {print $5}' | sed 's/%//')\n  \n  if [[ $usage -gt $threshold ]]; then\n    log_error \"Disk usage at ${usage}% (threshold: ${threshold}%)\"\n    # Send alert (email, slack, etc.)\n    return 1\n  fi\n  log_info \"Disk usage: ${usage}%\"\n}\n\n# Monitor service health\nmonitor_service() {\n  local service=$1\n  local max_retries=3\n  local retry_delay=5\n  \n  for ((i=1; i<=max_retries; i++)); do\n    if systemctl is-active --quiet \"$service\"; then\n      log_info \"$service is running\"\n      return 0\n    fi\n    log_error \"$service is not running (attempt $i/$max_retries)\"\n    sleep $retry_delay\n  done\n  return 1\n}\n```\n\n#### Data Processing\n```bash\n# CSV processing\nawk -F',' 'NR>1 {sum+=$3; count++} END {print \"Average:\", sum/count}' data.csv\n\n# JSON processing with jq\ncurl -s https://api.example.com/data | jq '.items[] | select(.status==\"active\") | .name'\n\n# Text manipulation\nsed -i 's/old_pattern/new_pattern/g' *.txt\ngrep -r \"TODO\" --include=\"*.js\" . | wc -l\n```\n\n### Powerful One-Liners\n\n```bash\n# Find and kill process by name\nps aux | grep '[p]rocess_name' | awk '{print $2}' | xargs kill -9\n\n# Port usage check\nlsof -i :8080 | grep LISTEN\n\n# Find biggest directories\ndu -h --max-depth=1 | sort -hr | head -10\n\n# Count lines of code by extension\nfind . -name '*.js' | xargs wc -l | tail -1\n\n# Remove duplicate lines while preserving order\nawk '!seen[$0]++' file.txt\n\n# Extract URLs from text\ngrep -oP 'https?://[^\\s]+' file.txt\n\n# Create backup with timestamp\ncp config.json config.json.$(date +%Y%m%d_%H%M%S)\n\n# Monitor file changes\nwatch -n 2 'ls -lh important_file.txt'\n\n# Find broken symlinks\nfind . -type l ! -exec test -e {} \\; -print\n\n# Compress files older than 30 days\nfind /var/log -name \"*.log\" -mtime +30 -exec gzip {} \\;\n```\n\n### Error Handling\n\n```bash\n# Robust error handling\nsafe_execute() {\n  local cmd=\"$*\"\n  local output\n  local exit_code\n  \n  log_debug \"Executing: $cmd\"\n  output=$(eval \"$cmd\" 2>&1)\n  exit_code=$?\n  \n  if [[ $exit_code -ne 0 ]]; then\n    log_error \"Command failed with exit code $exit_code: $cmd\"\n    log_error \"Output: $output\"\n    return $exit_code\n  fi\n  \n  log_debug \"Command succeeded: $cmd\"\n  echo \"$output\"\n  return 0\n}\n\n# Retry logic\nretry() {\n  local max_attempts=$1\n  shift\n  local cmd=\"$*\"\n  local attempt=1\n  \n  while [[ $attempt -le $max_attempts ]]; do\n    if eval \"$cmd\"; then\n      return 0\n    fi\n    log_error \"Attempt $attempt/$max_attempts failed: $cmd\"\n    ((attempt++))\n    sleep $((attempt * 2))\n  done\n  \n  log_error \"All $max_attempts attempts failed\"\n  return 1\n}\n\n# Usage\nretry 3 curl -f https://api.example.com/health\n```\n\n### Cross-Platform Compatibility\n\n```bash\n# Detect OS\ndetect_os() {\n  case \"$(uname -s)\" in\n    Linux*)     echo \"linux\" ;;\n    Darwin*)    echo \"macos\" ;;\n    CYGWIN*|MINGW*|MSYS*) echo \"windows\" ;;\n    *)          echo \"unknown\" ;;\n  esac\n}\n\n# Platform-specific commands\nOS=$(detect_os)\ncase $OS in\n  linux)\n    OPEN_CMD=\"xdg-open\"\n    COPY_CMD=\"xclip -selection clipboard\"\n    ;;\n  macos)\n    OPEN_CMD=\"open\"\n    COPY_CMD=\"pbcopy\"\n    ;;\n  windows)\n    OPEN_CMD=\"start\"\n    COPY_CMD=\"clip\"\n    ;;\nesac\n```\n\n## Examples\n\n### Example 1: Development Environment Setup Script\n\n```bash\n#!/usr/bin/env bash\nset -euo pipefail\n\n# dev-setup.sh - Automated development environment setup\n\nLOG_FILE=\"setup_$(date +%Y%m%d_%H%M%S).log\"\n\nlog() {\n  echo \"[$(date +'%Y-%m-%d %H:%M:%S')] $*\" | tee -a \"$LOG_FILE\"\n}\n\ncheck_command() {\n  if ! command -v \"$1\" &>/dev/null; then\n    log \"ERROR: $1 is not installed\"\n    return 1\n  fi\n  log \"âœ“ $1 is installed\"\n}\n\ninstall_node_tools() {\n  log \"Installing Node.js global packages...\"\n  npm install -g \\\n    typescript \\\n    eslint \\\n    prettier \\\n    nodemon \\\n    npm-check-updates\n}\n\nsetup_git_config() {\n  log \"Configuring Git...\"\n  git config --global core.autocrlf input\n  git config --global init.defaultBranch main\n  git config --global pull.rebase true\n  \n  # Set up git aliases\n  git config --global alias.st status\n  git config --global alias.co checkout\n  git config --global alias.br branch\n  git config --global alias.lg \"log --graph --oneline --decorate\"\n}\n\nclone_repos() {\n  log \"Cloning repositories...\"\n  local repos=(\n    \"https://github.com/org/project1.git\"\n    \"https://github.com/org/project2.git\"\n  )\n  \n  mkdir -p ~/projects\n  cd ~/projects\n  \n  for repo in \"${repos[@]}\"; do\n    local dir=$(basename \"$repo\" .git)\n    if [[ -d \"$dir\" ]]; then\n      log \"$dir already exists, skipping\"\n    else\n      log \"Cloning $repo...\"\n      git clone \"$repo\"\n    fi\n  done\n}\n\nmain() {\n  log \"Starting development environment setup...\"\n  \n  # Check prerequisites\n  check_command git || exit 1\n  check_command node || exit 1\n  check_command npm || exit 1\n  \n  # Run setup tasks\n  setup_git_config\n  install_node_tools\n  clone_repos\n  \n  log \"Setup completed successfully!\"\n  log \"Log file: $LOG_FILE\"\n}\n\nmain \"$@\"\n```\n\n### Example 2: Backup and Sync Script\n\n```bash\n#!/usr/bin/env bash\nset -euo pipefail\n\n# backup.sh - Intelligent backup with rotation and compression\n\nBACKUP_SOURCE=\"$HOME/projects\"\nBACKUP_DEST=\"$HOME/backups\"\nBACKUP_NAME=\"projects_$(date +%Y%m%d_%H%M%S)\"\nRETENTION_DAYS=30\nMAX_BACKUPS=10\n\ncreate_backup() {\n  local dest=\"$BACKUP_DEST/$BACKUP_NAME.tar.gz\"\n  \n  echo \"Creating backup: $dest\"\n  tar -czf \"$dest\" \\\n    --exclude=\"node_modules\" \\\n    --exclude=\".git\" \\\n    --exclude=\"*.log\" \\\n    --exclude=\"dist\" \\\n    --exclude=\"build\" \\\n    -C \"$(dirname \"$BACKUP_SOURCE\")\" \\\n    \"$(basename \"$BACKUP_SOURCE\")\"\n  \n  echo \"Backup created: $(du -h \"$dest\" | cut -f1)\"\n}\n\nrotate_backups() {\n  echo \"Rotating old backups...\"\n  \n  # Remove backups older than retention period\n  find \"$BACKUP_DEST\" -name \"projects_*.tar.gz\" -mtime +$RETENTION_DAYS -delete\n  \n  # Keep only the most recent backups\n  ls -t \"$BACKUP_DEST\"/projects_*.tar.gz | tail -n +$((MAX_BACKUPS + 1)) | xargs -r rm\n  \n  local count=$(ls \"$BACKUP_DEST\"/projects_*.tar.gz 2>/dev/null | wc -l)\n  echo \"Current backup count: $count\"\n}\n\nverify_backup() {\n  local backup_file=\"$BACKUP_DEST/$BACKUP_NAME.tar.gz\"\n  \n  echo \"Verifying backup integrity...\"\n  if tar -tzf \"$backup_file\" >/dev/null; then\n    echo \"âœ“ Backup verification passed\"\n    return 0\n  else\n    echo \"âœ— Backup verification failed!\"\n    return 1\n  fi\n}\n\nmain() {\n  mkdir -p \"$BACKUP_DEST\"\n  \n  create_backup\n  verify_backup\n  rotate_backups\n  \n  echo \"Backup completed successfully!\"\n}\n\nmain \"$@\"\n```\n\n### Example 3: Database Maintenance Script\n\n```bash\n#!/usr/bin/env bash\nset -euo pipefail\n\n# db-maintenance.sh - Database backup and optimization\n\nDB_HOST=\"localhost\"\nDB_USER=\"admin\"\nDB_NAME=\"myapp\"\nBACKUP_DIR=\"/var/backups/mysql\"\nLOG_FILE=\"/var/log/db-maintenance.log\"\n\nlog() {\n  echo \"[$(date +'%Y-%m-%d %H:%M:%S')] $*\" | tee -a \"$LOG_FILE\"\n}\n\nbackup_database() {\n  local backup_file=\"$BACKUP_DIR/${DB_NAME}_$(date +%Y%m%d_%H%M%S).sql.gz\"\n  \n  log \"Starting database backup: $DB_NAME\"\n  \n  mysqldump \\\n    --host=\"$DB_HOST\" \\\n    --user=\"$DB_USER\" \\\n    --single-transaction \\\n    --quick \\\n    --lock-tables=false \\\n    \"$DB_NAME\" | gzip > \"$backup_file\"\n  \n  if [[ -f \"$backup_file\" ]]; then\n    local size=$(du -h \"$backup_file\" | cut -f1)\n    log \"Backup completed: $backup_file ($size)\"\n  else\n    log \"ERROR: Backup failed\"\n    return 1\n  fi\n}\n\noptimize_tables() {\n  log \"Optimizing database tables...\"\n  \n  mysql --host=\"$DB_HOST\" --user=\"$DB_USER\" \"$DB_NAME\" <<EOF\n    SELECT CONCAT('OPTIMIZE TABLE ', table_name, ';') \n    FROM information_schema.tables \n    WHERE table_schema='$DB_NAME';\nEOF\n  \n  log \"Table optimization completed\"\n}\n\ncleanup_old_backups() {\n  log \"Cleaning up backups older than 7 days...\"\n  find \"$BACKUP_DIR\" -name \"${DB_NAME}_*.sql.gz\" -mtime +7 -delete\n  \n  local count=$(ls \"$BACKUP_DIR\"/${DB_NAME}_*.sql.gz 2>/dev/null | wc -l)\n  log \"Remaining backups: $count\"\n}\n\nmain() {\n  mkdir -p \"$BACKUP_DIR\"\n  \n  backup_database\n  optimize_tables\n  cleanup_old_backups\n  \n  log \"Database maintenance completed\"\n}\n\nmain \"$@\"\n```\n\n### Example 4: CI/CD Deployment Script\n\n```bash\n#!/usr/bin/env bash\nset -euo pipefail\n\n# deploy.sh - Production deployment script\n\nENVIRONMENT=${1:-staging}\nAPP_NAME=\"myapp\"\nDEPLOY_USER=\"deploy\"\nDEPLOY_HOST=\"app.example.com\"\nDEPLOY_PATH=\"/var/www/$APP_NAME\"\nHEALTH_CHECK_URL=\"https://app.example.com/health\"\n\nlog_info() { echo \"[INFO] $*\"; }\nlog_error() { echo \"[ERROR] $*\" >&2; }\n\npre_deploy_checks() {\n  log_info \"Running pre-deployment checks...\"\n  \n  # Check if tests pass\n  if ! npm test; then\n    log_error \"Tests failed, aborting deployment\"\n    exit 1\n  fi\n  \n  # Check if build succeeds\n  if ! npm run build; then\n    log_error \"Build failed, aborting deployment\"\n    exit 1\n  fi\n  \n  log_info \"âœ“ Pre-deployment checks passed\"\n}\n\ndeploy_application() {\n  log_info \"Deploying to $ENVIRONMENT...\"\n  \n  # Create deployment package\n  local package=\"deploy_$(date +%Y%m%d_%H%M%S).tar.gz\"\n  tar -czf \"$package\" \\\n    --exclude=\"node_modules\" \\\n    --exclude=\".git\" \\\n    dist/ package.json package-lock.json\n  \n  # Upload to server\n  scp \"$package\" \"$DEPLOY_USER@$DEPLOY_HOST:/tmp/\"\n  \n  # Execute deployment on remote server\n  ssh \"$DEPLOY_USER@$DEPLOY_HOST\" <<EOF\n    set -e\n    cd $DEPLOY_PATH\n    \n    # Backup current version\n    if [[ -d \"current\" ]]; then\n      mv current \"backup_\\$(date +%Y%m%d_%H%M%S)\"\n    fi\n    \n    # Extract new version\n    mkdir -p current\n    tar -xzf \"/tmp/$package\" -C current\n    \n    # Install dependencies\n    cd current\n    npm ci --production\n    \n    # Restart application\n    pm2 reload $APP_NAME || pm2 start ecosystem.config.js\n    \n    # Cleanup\n    rm \"/tmp/$package\"\nEOF\n  \n  rm \"$package\"\n  log_info \"âœ“ Deployment completed\"\n}\n\nhealth_check() {\n  log_info \"Performing health check...\"\n  \n  local max_attempts=10\n  local attempt=1\n  \n  while [[ $attempt -le $max_attempts ]]; do\n    if curl -f -s \"$HEALTH_CHECK_URL\" >/dev/null; then\n      log_info \"âœ“ Health check passed\"\n      return 0\n    fi\n    log_info \"Health check attempt $attempt/$max_attempts failed, retrying...\"\n    sleep 5\n    ((attempt++))\n  done\n  \n  log_error \"Health check failed after $max_attempts attempts\"\n  return 1\n}\n\nrollback() {\n  log_error \"Deployment failed, initiating rollback...\"\n  \n  ssh \"$DEPLOY_USER@$DEPLOY_HOST\" <<EOF\n    cd $DEPLOY_PATH\n    rm -rf current\n    mv \\$(ls -t backup_* | head -1) current\n    pm2 reload $APP_NAME\nEOF\n  \n  log_info \"Rollback completed\"\n}\n\nmain() {\n  log_info \"Starting deployment to $ENVIRONMENT\"\n  \n  pre_deploy_checks\n  \n  if deploy_application && health_check; then\n    log_info \"ðŸš€ Deployment successful!\"\n  else\n    rollback\n    exit 1\n  fi\n}\n\nmain \"$@\"\n```\n\n### Example 5: Log Analysis and Monitoring\n\n```bash\n#!/usr/bin/env bash\n\n# log-analyzer.sh - Analyze application logs for errors and patterns\n\nLOG_DIR=\"/var/log/app\"\nREPORT_FILE=\"log_report_$(date +%Y%m%d).txt\"\n\ngenerate_report() {\n  cat > \"$REPORT_FILE\" <<EOF\nLog Analysis Report\nGenerated: $(date)\n=====================================\n\nERROR Summary:\n$(grep -h \"ERROR\" \"$LOG_DIR\"/*.log 2>/dev/null | wc -l) total errors\n\nTop 10 Error Messages:\n$(grep -h \"ERROR\" \"$LOG_DIR\"/*.log 2>/dev/null | sort | uniq -c | sort -rn | head -10)\n\nWARNING Summary:\n$(grep -h \"WARN\" \"$LOG_DIR\"/*.log 2>/dev/null | wc -l) total warnings\n\nTop 10 Warning Messages:\n$(grep -h \"WARN\" \"$LOG_DIR\"/*.log 2>/dev/null | sort | uniq -c | sort -rn | head -10)\n\n5XX Errors (last 24h):\n$(find \"$LOG_DIR\" -name \"*.log\" -mtime -1 -exec grep -h \"HTTP/[0-9.]* 5[0-9][0-9]\" {} \\; | wc -l)\n\nTop 10 Slowest Endpoints:\n$(grep -h \"response_time\" \"$LOG_DIR\"/*.log 2>/dev/null | awk '{print $5, $7}' | sort -k2 -rn | head -10)\n\nEOF\n\n  cat \"$REPORT_FILE\"\n}\n\nmain() {\n  generate_report\n  echo \"\"\n  echo \"Report saved to: $REPORT_FILE\"\n}\n\nmain \"$@\"\n```\n\nThese examples demonstrate production-ready shell scripts with proper error handling, logging, and best practices for common automation tasks.",
  "prompt": "A skill that provides comprehensive guidance on writing bash/shell scripts for automation, including one-liners, file processing, git automation, deployment scripts, and production-ready error handling patterns.",
  "createdAt": "2024-01-15T10:00:00.000Z",
  "published": true
}
