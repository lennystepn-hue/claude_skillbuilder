{
  "id": "project-code-estimation",
  "name": "Code Estimation",
  "description": "Time estimation techniques for software development including story points, t-shirt sizing, complexity analysis, velocity tracking, and estimation best practices for accurate project planning",
  "category": "Project",
  "content": "---\nname: Code Estimation\ndescription: Time estimation techniques for software development including story points, t-shirt sizing, complexity analysis, velocity tracking, and estimation best practices for accurate project planning\ncategory: Project\n---\n\n# Code Estimation\n\n## Overview\n\nThis skill provides comprehensive guidance on estimating software development effort, from high-level features to granular tasks. It covers multiple estimation techniques, complexity analysis, velocity tracking, and methods to improve estimation accuracy over time.\n\n## Activation\n\nThis skill activates when you need to:\n- Estimate user stories or features\n- Analyze code complexity for estimation\n- Calculate project timelines\n- Conduct planning poker sessions\n- Track and improve team velocity\n- Identify estimation risks and uncertainties\n- Compare estimates with actuals for improvement\n\n## Instructions\n\nWhen activated, this skill will:\n\n1. **Choose Estimation Method**\n   - Story points for relative sizing\n   - T-shirt sizing for quick estimates\n   - Hour-based for task-level detail\n   - PERT (three-point) for uncertainty\n\n2. **Analyze Complexity**\n   - Technical complexity assessment\n   - Domain/business logic complexity\n   - Integration complexity\n   - Testing complexity\n   - Unknown factors and risks\n\n3. **Apply Estimation Technique**\n   - Guide planning poker sessions\n   - Facilitate team consensus\n   - Consider historical data\n   - Account for team capacity\n\n4. **Calculate Timelines**\n   - Convert story points to time\n   - Apply team velocity\n   - Add buffers for uncertainty\n   - Create realistic schedules\n\n5. **Track and Improve**\n   - Compare estimates vs actuals\n   - Identify patterns in over/under estimation\n   - Adjust future estimates\n   - Improve team calibration\n\n## Estimation Techniques\n\n### 1. Story Points (Fibonacci Sequence)\n\n**Scale**: 1, 2, 3, 5, 8, 13, 21, 40, 100\n\n**Guidelines**:\n```markdown\n1 point - Trivial change\n- Simple text change\n- Minor CSS adjustment\n- Configuration update\n- Example: Change button color\n\n2 points - Simple task\n- Small, well-understood change\n- Minimal testing required\n- No dependencies\n- Example: Add validation to existing form field\n\n3 points - Straightforward feature\n- Moderate complexity\n- Some testing required\n- Few dependencies\n- Example: Add new field to database and API\n\n5 points - Standard feature\n- Average complexity\n- Multiple components affected\n- Integration testing needed\n- Example: Create new CRUD endpoint with UI\n\n8 points - Complex feature\n- High complexity\n- Multiple integrations\n- Significant testing\n- Some unknowns\n- Example: Implement third-party payment integration\n\n13 points - Very complex feature\n- Very high complexity\n- Many unknowns\n- Cross-team dependencies\n- Extensive testing\n- Example: Build real-time notification system\n\n21+ points - Epic/Should be split\n- Too large for one sprint\n- Many unknowns\n- Should be broken down\n- Example: Redesign entire authentication system\n```\n\n### 2. T-Shirt Sizing\n\n**Scale**: XS, S, M, L, XL, XXL\n\n```markdown\nXS (Extra Small) - 1-2 hours\n- Quick fix or trivial change\n- Example: Fix typo, update constant\n\nS (Small) - 2-4 hours\n- Small feature or simple bug fix\n- Example: Add sorting to existing table\n\nM (Medium) - 1-2 days\n- Standard feature development\n- Example: Create new form with validation\n\nL (Large) - 3-5 days\n- Complex feature with multiple parts\n- Example: Implement search with filters\n\nXL (Extra Large) - 1-2 weeks\n- Very complex feature or significant refactor\n- Example: Build analytics dashboard\n\nXXL (Extra Extra Large) - 2+ weeks\n- Should be split into smaller pieces\n- Example: Migrate to new framework\n```\n\n### 3. Three-Point Estimation (PERT)\n\n**Formula**: (Optimistic + 4×Most Likely + Pessimistic) / 6\n\n```markdown\nFor each task, estimate:\n\nOptimistic (O): Best-case scenario, everything goes perfectly\nMost Likely (M): Realistic estimate with normal challenges\nPessimistic (P): Worst-case scenario, everything goes wrong\n\nExpected Time = (O + 4M + P) / 6\n\nExample:\nTask: Implement user authentication\n- Optimistic: 8 hours (using existing library, no issues)\n- Most Likely: 16 hours (some debugging, testing time)\n- Pessimistic: 32 hours (library issues, security requirements)\n- Expected: (8 + 4×16 + 32) / 6 = 14.7 hours ≈ 15 hours\n```\n\n### 4. Planning Poker\n\n**Process**:\n```markdown\n1. Product Owner presents user story\n2. Team asks clarifying questions\n3. Each team member selects estimate card (secretly)\n4. All reveal cards simultaneously\n5. Discuss outliers (highest and lowest explain reasoning)\n6. Re-estimate if needed\n7. Reach consensus\n\nBenefits:\n- Engages whole team\n- Surfaces different perspectives\n- Prevents anchoring bias\n- Builds shared understanding\n```\n\n## Complexity Analysis Framework\n\n### Complexity Factors Matrix\n\n```markdown\n| Factor | Low (1x) | Medium (2x) | High (3x) | Very High (5x) |\n|--------|----------|-------------|-----------|----------------|\n| **Technical Complexity** |\n| Code | Simple CRUD | Business logic | Algorithms | Distributed systems |\n| Architecture | Existing pattern | New pattern | New architecture | Research needed |\n| Technology | Familiar stack | Some new tech | Mostly new tech | All new tech |\n\n| **Domain Complexity** |\n| Business Rules | Simple | Moderate | Complex | Very complex |\n| Edge Cases | Few (2-3) | Some (4-6) | Many (7-10) | Extensive (10+) |\n| Validation | Basic | Moderate | Complex | Very complex |\n\n| **Integration Complexity** |\n| External APIs | None | 1-2 APIs | 3-5 APIs | 5+ APIs |\n| Database | Single table | Few tables | Many tables | Multiple DBs |\n| Dependencies | Independent | 1-2 deps | 3-5 deps | 5+ deps |\n\n| **Testing Complexity** |\n| Unit Tests | Straightforward | Moderate mocking | Complex mocking | Very difficult |\n| Integration | Simple | Moderate | Complex setup | Very complex |\n| E2E | Not needed | Simple flow | Multiple flows | Critical flows |\n\n| **Uncertainty** |\n| Requirements | Clear | Mostly clear | Some unclear | Very unclear |\n| Technology | Known | Mostly known | Some unknown | Largely unknown |\n| Risk | Low | Medium | High | Very high |\n```\n\n### Complexity Calculation Example\n\n```markdown\nFeature: Real-time Collaborative Document Editing\n\nFactors:\n- Technical: Very High (5x) - WebSocket, CRDT algorithms, conflict resolution\n- Domain: High (3x) - Complex collaboration rules, permissions\n- Integration: Medium (2x) - 2 external services (auth, storage)\n- Testing: High (3x) - Complex concurrent scenarios\n- Uncertainty: High (3x) - New to team, some unknowns\n\nBase estimate (simple CRUD): 5 points\n\nComplexity multipliers:\nAverage multiplier = (5 + 3 + 2 + 3 + 3) / 5 = 3.2x\n\nAdjusted estimate: 5 × 3.2 = 16 points\nRound to nearest Fibonacci: 13 points\n\nConfidence level: Medium (due to high uncertainty)\nRecommendation: Consider a spike (research task) first\n```\n\n## Templates\n\n### Estimation Session Template\n\n```markdown\n# Estimation Session - Sprint [Number]\n\nDate: [Date]\nAttendees: [Team members]\nFacilitator: [Name]\n\n## Stories to Estimate\n\n### Story 1: [Story ID] - [Title]\n\n**Description**: [Brief description]\n\n**Acceptance Criteria**:\n- [Criterion 1]\n- [Criterion 2]\n- [Criterion 3]\n\n**Discussion Points**:\n- [Question/concern raised]\n- [Technical consideration]\n- [Dependency noted]\n\n**Complexity Factors**:\n- Technical: [Low/Medium/High/Very High]\n- Domain: [Low/Medium/High/Very High]\n- Integration: [Low/Medium/High/Very High]\n- Testing: [Low/Medium/High/Very High]\n- Uncertainty: [Low/Medium/High/Very High]\n\n**Planning Poker Results**:\n- Round 1: [3, 5, 5, 8, 5] → Discussion\n- Round 2: [5, 5, 5, 5, 5] → Consensus\n\n**Final Estimate**: 5 points\n**Confidence**: High/Medium/Low\n**Notes**: [Any important notes or assumptions]\n\n---\n\n[Repeat for each story]\n\n## Summary\n- Total stories estimated: [count]\n- Total story points: [sum]\n- Average confidence: [High/Medium/Low]\n- Action items: [List any follow-up actions]\n```\n\n### Velocity Tracking Template\n\n```markdown\n# Team Velocity Tracker\n\n## Current Sprint: Sprint [Number]\n\n**Commitment**: [X] points\n**Completed**: [Y] points\n**Completion Rate**: [Y/X × 100]%\n\n## Historical Velocity\n\n| Sprint | Committed | Completed | % Complete | Notes |\n|--------|-----------|-----------|------------|-------|\n| 20 | 40 | 38 | 95% | Holiday week |\n| 21 | 42 | 42 | 100% | Great sprint! |\n| 22 | 45 | 36 | 80% | Production issues |\n| 23 | 40 | 41 | 102% | Easier stories |\n| 24 | 42 | 40 | 95% | Current sprint |\n\n## Velocity Metrics\n\n**Average Velocity (last 5 sprints)**: 39.4 points\n**Median Velocity**: 40 points\n**Standard Deviation**: 2.4 points\n**Trend**: Stable ↔️\n\n**Recommended Sprint Commitment**: 38-42 points (median ± 1 std dev)\n\n## Factors Affecting Velocity\n\n**Positive Factors**:\n- Reduced meetings\n- Better story refinement\n- Improved team collaboration\n\n**Negative Factors**:\n- Team member on PTO\n- Production support load\n- Unclear requirements\n\n## Improvement Actions\n- [ ] Improve backlog refinement process\n- [ ] Reduce production support interruptions\n- [ ] Better estimation calibration for new tech\n```\n\n### Estimate vs Actual Tracker\n\n```markdown\n# Estimation Accuracy Tracking\n\n## Sprint [Number] - Post-Sprint Analysis\n\n| Story ID | Title | Estimated | Actual | Variance | Reason for Variance |\n|----------|-------|-----------|--------|----------|---------------------|\n| US-301 | User Login | 5 pts | 5 pts | 0% | Accurate |\n| US-302 | Password Reset | 3 pts | 5 pts | +67% | Forgot email templates |\n| US-303 | Profile Page | 8 pts | 6 pts | -25% | Simpler than expected |\n| US-304 | Dashboard | 8 pts | 13 pts | +63% | Complex data aggregation |\n| US-305 | Settings | 5 pts | 5 pts | 0% | Accurate |\n\n**Total Estimated**: 29 points\n**Total Actual**: 34 points\n**Overall Variance**: +17%\n\n## Analysis\n\n**Overestimated**: 1 story (US-303)\n- Reason: Reused more components than anticipated\n\n**Underestimated**: 2 stories (US-302, US-304)\n- Pattern: Missing non-obvious requirements (email templates, data complexity)\n- Action: Improve requirement gathering, ask about email/notification needs\n\n**Accurate**: 2 stories (US-301, US-305)\n\n## Lessons Learned\n\n1. **Better Questions**: Ask about email notifications and data aggregation needs\n2. **Component Inventory**: Maintain list of reusable components\n3. **Complexity Checklist**: Use checklist for complexity factors\n\n## Adjustments for Next Sprint\n- Add 20% buffer for stories involving data aggregation\n- Check for email/notification requirements explicitly\n- Review component library before estimating UI work\n```\n\n## Examples\n\n### Example 1: Planning Poker Session\n\n```markdown\n# Story: US-456 - Implement Shopping Cart\n\n## Product Owner Presentation\n\"Users need to add multiple items to a cart, update quantities, remove items, and see real-time total calculation including tax and shipping.\"\n\n## Team Questions\nQ: \"Does the cart need to persist if user logs out?\"\nA: \"Yes, stored in database, not just session.\"\n\nQ: \"Do we need to handle inventory checks?\"\nA: \"Yes, show if item becomes unavailable while in cart.\"\n\nQ: \"Any coupon/discount codes?\"\nA: \"Not in this story, that's US-457.\"\n\nQ: \"What about abandoned cart emails?\"\nA: \"Not in this story.\"\n\n## Initial Estimates (Round 1)\n- Dev A: 8 points (\"Seems like standard feature\")\n- Dev B: 5 points (\"We have similar cart logic in wishlist\")\n- Dev C: 8 points (\"Database persistence adds complexity\")\n- Dev D: 13 points (\"Inventory checks could be tricky\")\n\n## Discussion\n\n**Dev D (13 points)**: \"I'm concerned about real-time inventory checks. What if inventory service is slow or down? Do we cache? What about race conditions?\"\n\n**Dev B (5 points)**: \"Good point. I was thinking simple, but real-time inventory adds complexity. We'd need:\n- Webhook from inventory service\n- Cache with TTL\n- Queue for async updates\n- Error handling for service down\"\n\n**Dev A**: \"Database persistence is straightforward - just a cart_items table. But the inventory integration is complex.\"\n\n**Team Agreement**: The inventory check is a separate concern that adds significant complexity.\n\n## Revised Estimates (Round 2)\n- Dev A: 8 points\n- Dev B: 8 points\n- Dev C: 8 points\n- Dev D: 8 points\n\n## Consensus: 8 points\n\n**Breakdown**:\n- Database schema & API: 3 points\n- Frontend cart UI: 2 points\n- Real-time total calculation: 1 point\n- Inventory integration: 2 points\n- Testing: included in above\n\n**Assumptions Documented**:\n- Inventory service has webhook for stock updates\n- 5-minute cache TTL acceptable\n- If inventory service down, show \"Unable to verify availability\"\n\n**Confidence**: Medium (inventory integration has some unknowns)\n```\n\n### Example 2: T-Shirt Sizing for Roadmap\n\n```markdown\n# Q2 Roadmap - Initial Sizing\n\n## Feature: Mobile App Push Notifications\n\n**Size**: L (Large)\n\n**Reasoning**:\n- Need to integrate with FCM (Firebase) and APNs (Apple)\n- Backend: notification service, delivery tracking\n- Mobile: Handle notification receipt, deep linking\n- Testing: Real device testing needed\n- Some team members new to push notifications\n\n**Rough estimate**: 3-5 days per platform = 6-10 days total\n**Story points equivalent**: ~21-34 points\n**Recommendation**: Break into smaller features:\n  - Basic push notifications (8 pts)\n  - Deep linking (5 pts)\n  - Rich notifications with images (5 pts)\n  - Notification preferences (3 pts)\n\n---\n\n## Feature: Advanced Search Filters\n\n**Size**: M (Medium)\n\n**Reasoning**:\n- UI is straightforward (filter sidebar)\n- Backend filter logic moderate complexity\n- Need to update search API\n- Elasticsearch query building\n- Similar to features we've built\n\n**Rough estimate**: 1-2 days\n**Story points equivalent**: ~8-13 points\n**Recommendation**: Single story, estimate in detail during refinement\n\n---\n\n## Feature: Fix Login Bug\n\n**Size**: S (Small)\n\n**Reasoning**:\n- Bug is reproducible and understood\n- Fix is in known area of codebase\n- Minimal testing needed\n\n**Rough estimate**: 2-4 hours\n**Story points equivalent**: ~2-3 points\n**Recommendation**: Include in next sprint\n```\n\n### Example 3: PERT Estimation with Uncertainty\n\n```markdown\n# Story: US-789 - Migrate from REST to GraphQL\n\n## Three-Point Estimation\n\nThis is a significant change with many unknowns. Using PERT to account for uncertainty.\n\n### Tasks with Estimates\n\n**Task 1: Set up GraphQL server**\n- Optimistic: 4h (use Apollo, straightforward setup)\n- Most Likely: 8h (some configuration, learning curve)\n- Pessimistic: 16h (compatibility issues with existing stack)\n- **Expected**: (4 + 4×8 + 16) / 6 = 8.7h ≈ 9h\n\n**Task 2: Convert REST endpoints to GraphQL resolvers**\n- Optimistic: 16h (straightforward conversion)\n- Most Likely: 32h (20 endpoints, some complex logic)\n- Pessimistic: 64h (edge cases, testing issues)\n- **Expected**: (16 + 4×32 + 64) / 6 = 34.7h ≈ 35h\n\n**Task 3: Update frontend to use GraphQL**\n- Optimistic: 12h (replace fetch calls with GraphQL queries)\n- Most Likely: 24h (refactor data fetching, update state management)\n- Pessimistic: 40h (major refactoring needed)\n- **Expected**: (12 + 4×24 + 40) / 6 = 24.7h ≈ 25h\n\n**Task 4: Update tests**\n- Optimistic: 8h (update mocks, mostly passing)\n- Most Likely: 16h (rewrite integration tests)\n- Pessimistic: 32h (major test refactoring)\n- **Expected**: (8 + 4×16 + 32) / 6 = 17.3h ≈ 17h\n\n**Task 5: Documentation and deployment**\n- Optimistic: 4h (simple docs, smooth deploy)\n- Most Likely: 8h (comprehensive docs, testing)\n- Pessimistic: 16h (deployment issues)\n- **Expected**: (4 + 4×8 + 16) / 6 = 8.7h ≈ 9h\n\n### Total Estimate\n**Sum of Expected Times**: 9 + 35 + 25 + 17 + 9 = 95 hours\n\n**Convert to Story Points**:\n- Team velocity: 40 points per sprint\n- Team capacity: 160 hours per sprint (4 devs × 40h)\n- Points per hour: 40 / 160 = 0.25\n- Story points: 95h × 0.25 = 23.75 ≈ 21 points\n\n**Recommendation**: This is too large for one sprint. Split into:\n1. GraphQL server setup + 5 critical endpoints (8 pts)\n2. Remaining endpoints (8 pts)\n3. Frontend migration (5 pts)\n4. Testing & documentation (3 pts)\n\nTotal: 24 points across 2 sprints\n```\n\n### Example 4: Velocity-Based Timeline Calculation\n\n```markdown\n# Project: Customer Portal Redesign\n\n## Epic Breakdown\n\n| Epic | Story Points |\n|------|-------------|\n| User Authentication | 21 |\n| Dashboard | 34 |\n| Account Management | 21 |\n| Billing & Invoices | 34 |\n| Support Tickets | 21 |\n| Admin Panel | 21 |\n| **Total** | **152 points** |\n\n## Team Velocity Analysis\n\n**Historical Velocity (last 6 sprints)**:\n- Sprint 18: 38 points\n- Sprint 19: 42 points\n- Sprint 20: 36 points (holiday)\n- Sprint 21: 40 points\n- Sprint 22: 41 points\n- Sprint 23: 39 points\n\n**Average Velocity**: 39.3 points\n**Median Velocity**: 39.5 points\n**Conservative Estimate**: 38 points (to be safe)\n\n## Timeline Calculation\n\n**Optimistic** (using max velocity of 42 pts):\n152 points ÷ 42 points/sprint = 3.6 sprints → **4 sprints**\n\n**Realistic** (using median velocity of 39.5 pts):\n152 points ÷ 39.5 points/sprint = 3.8 sprints → **4 sprints**\n\n**Conservative** (using 38 pts + 20% buffer):\n152 points ÷ 38 points/sprint = 4 sprints\nWith 20% buffer: 4 × 1.2 = 4.8 sprints → **5 sprints**\n\n## Recommendation\n\n**Timeline**: 4-5 sprints (8-10 weeks)\n**Start Date**: Sprint 24 (Feb 1)\n**Target Completion**: Sprint 28 (Apr 15)\n**Buffer**: 1 sprint (2 weeks)\n\n**Confidence**: Medium-High\n- Well-understood domain\n- Stable team\n- Clear requirements\n- Similar projects completed successfully\n\n**Risks**:\n- Holiday in Sprint 26 (reduce velocity to 35 pts)\n- Billing integration complexity might increase scope\n- New developer joining Sprint 25 (onboarding overhead)\n\n**Adjusted Timeline with Risks**:\n- Sprint 24: 38 pts\n- Sprint 25: 35 pts (new dev onboarding)\n- Sprint 26: 35 pts (holiday)\n- Sprint 27: 40 pts\n- Sprint 28: 20 pts (buffer/polish)\n\nTotal capacity: 168 points (enough for 152 + 10% buffer)\n```\n\n### Example 5: Complexity-Based Estimation\n\n```markdown\n# Story: US-890 - Real-time Analytics Dashboard\n\n## Complexity Analysis\n\n### Technical Complexity: Very High (5x)\n- WebSocket connections for real-time updates\n- Complex data aggregation across multiple sources\n- Performance optimization required (1000s of data points)\n- Caching strategy needed\n\n### Domain Complexity: High (3x)\n- 8 different metric types\n- Custom date range logic\n- Multiple aggregation levels (hourly, daily, weekly, monthly)\n- Complex business rules for calculations\n\n### Integration Complexity: High (3x)\n- 4 different data sources\n- External analytics API\n- Real-time event stream\n- Legacy database queries\n\n### Testing Complexity: High (3x)\n- Performance testing required\n- Real-time behavior hard to test\n- Need to mock multiple data sources\n- E2E tests complex\n\n### Uncertainty: Medium (2x)\n- Team has built dashboards before\n- WebSocket technology is new to team\n- Some requirements still being clarified\n\n## Estimation Calculation\n\n**Base Estimate** (simple dashboard): 8 points\n\n**Complexity Multiplier**:\nAverage = (5 + 3 + 3 + 3 + 2) / 5 = 3.2x\n\n**Adjusted Estimate**: 8 × 3.2 = 25.6 points\n\n**Nearest Fibonacci**: 21 points\n\n## Risk Assessment\n\n**High Risk Areas**:\n1. Real-time performance with 1000s of concurrent users\n2. Data aggregation query optimization\n3. WebSocket scaling\n\n**Mitigation**:\n- Create spike story for WebSocket POC (3 pts)\n- Load testing plan\n- Consider alternative: polling instead of WebSocket\n\n## Final Recommendation\n\n**Spike First**: US-891 - WebSocket POC (3 pts)\n- Prove real-time architecture\n- Load test with expected traffic\n- Document findings\n\n**Then Estimate Main Story**: Based on spike findings\n- If spike successful: 21 points\n- If spike reveals issues: Split into smaller stories\n\n**Alternative Approach**: \nSplit into MVP + enhancements:\n1. Basic dashboard with polling (8 pts)\n2. Real-time updates with WebSocket (8 pts)\n3. Performance optimization (5 pts)\n```\n\n## Best Practices\n\n1. **Use Relative Estimation**\n   - Compare to similar past work\n   - Use reference stories for calibration\n   - Focus on relative size, not absolute time\n\n2. **Involve the Whole Team**\n   - Different perspectives improve accuracy\n   - Builds shared understanding\n   - Surfaces hidden complexity\n\n3. **Estimate Regularly**\n   - Fresh context improves accuracy\n   - Don't estimate too far in advance\n   - Re-estimate if requirements change\n\n4. **Track Actuals**\n   - Compare estimates to actuals\n   - Identify patterns in over/under estimation\n   - Continuously improve calibration\n\n5. **Account for Uncertainty**\n   - Add buffers for high-uncertainty items\n   - Consider spike stories for unknowns\n   - Use PERT for critical path items\n\n6. **Don't Over-Optimize**\n   - Estimates are estimates, not commitments\n   - Some variance is normal and expected\n   - Focus on trends, not individual estimates\n\n7. **Break Down Large Items**\n   - Stories over 13 points should be split\n   - Smaller items are easier to estimate\n   - Reduces risk and improves predictability\n\n## Common Pitfalls\n\n- **Anchoring Bias**: First estimate influences others\n- **Optimism Bias**: Assuming best-case scenario\n- **Recency Bias**: Overweighting recent experiences\n- **Groupthink**: Team converges without real discussion\n- **Ignoring Complexity**: Underestimating non-obvious complexity\n- **Forgetting Testing**: Not including testing time\n- **Pressure to Commit**: Estimating low due to deadline pressure\n\n## Estimation Maturity Model\n\n**Level 1 - Guessing**: Wild guesses, no historical data\n**Level 2 - Individual Estimates**: One person estimates, often inaccurate\n**Level 3 - Team Estimation**: Team estimates together, improving\n**Level 4 - Data-Driven**: Using velocity and historical data\n**Level 5 - Predictive**: Consistently accurate, continuous improvement\n",
  "prompt": "A skill that provides comprehensive software estimation techniques including story points with Fibonacci sequence, t-shirt sizing, three-point PERT estimation, and planning poker facilitation. Includes complexity analysis framework evaluating technical, domain, integration, testing, and uncertainty factors. Provides templates for estimation sessions, velocity tracking, estimate vs actual analysis, and practical examples for shopping carts, GraphQL migrations, analytics dashboards, and project timeline calculations with team velocity.",
  "createdAt": "2024-01-15T10:00:00.000Z",
  "published": true
}