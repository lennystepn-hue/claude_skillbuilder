{
  "id": "ai-finetuning",
  "name": "model-finetuning",
  "description": "Fine-tune language models for specific tasks",
  "category": "AI",
  "content": "---\nname: model-finetuning\ndescription: Fine-tune LLMs for specific tasks\ncategory: AI\n---\n\n# Model Fine-tuning\n\n## Overview\nFine-tune language models on custom data to improve performance on specific tasks.\n\n## Activation\nActivates when user mentions \"fine-tune\", \"fine-tuning\", \"custom model\", \"train model\", \"LoRA\", \"PEFT\", or \"instruction tuning\".\n\n## Instructions\n\n### Fine-tuning Options\n1. **Full Fine-tuning**: Update all weights (expensive)\n2. **LoRA/QLoRA**: Low-rank adaptation (efficient)\n3. **Prefix Tuning**: Add trainable prefix tokens\n4. **Prompt Tuning**: Learn soft prompts\n5. **API Fine-tuning**: OpenAI, Anthropic APIs\n\n### Data Preparation\n- Minimum 50-100 high-quality examples\n- Consistent format (instruction, input, output)\n- Diverse examples covering edge cases\n- Clean, validated data\n\n## Examples\n\n**OpenAI Fine-tuning:**\n```python\nimport json\nfrom openai import OpenAI\n\ndef prepare_training_data(examples, output_file):\n    \"\"\"Prepare JSONL file for OpenAI fine-tuning.\"\"\"\n    with open(output_file, 'w') as f:\n        for ex in examples:\n            entry = {\n                \"messages\": [\n                    {\"role\": \"system\", \"content\": ex.get(\"system\", \"You are a helpful assistant.\")},\n                    {\"role\": \"user\", \"content\": ex[\"input\"]},\n                    {\"role\": \"assistant\", \"content\": ex[\"output\"]}\n                ]\n            }\n            f.write(json.dumps(entry) + \"\\n\")\n\ndef fine_tune_openai(training_file, model=\"gpt-4o-mini-2024-07-18\"):\n    \"\"\"Create and monitor fine-tuning job.\"\"\"\n    client = OpenAI()\n    \n    # Upload file\n    file = client.files.create(\n        file=open(training_file, \"rb\"),\n        purpose=\"fine-tune\"\n    )\n    \n    # Create fine-tuning job\n    job = client.fine_tuning.jobs.create(\n        training_file=file.id,\n        model=model,\n        hyperparameters={\n            \"n_epochs\": 3,\n            \"batch_size\": 4,\n            \"learning_rate_multiplier\": 1.0\n        }\n    )\n    \n    print(f\"Job ID: {job.id}\")\n    return job\n\ndef check_status(job_id):\n    client = OpenAI()\n    job = client.fine_tuning.jobs.retrieve(job_id)\n    print(f\"Status: {job.status}\")\n    if job.fine_tuned_model:\n        print(f\"Model: {job.fine_tuned_model}\")\n    return job\n\n# Usage\nexamples = [\n    {\"input\": \"Summarize this code\", \"output\": \"This function calculates...\"},\n    {\"input\": \"What does this do?\", \"output\": \"This is a sorting algorithm...\"}\n]\nprepare_training_data(examples, \"training.jsonl\")\njob = fine_tune_openai(\"training.jsonl\")\n```\n\n**LoRA Fine-tuning with Hugging Face:**\n```python\nfrom transformers import (\n    AutoModelForCausalLM, AutoTokenizer,\n    TrainingArguments, Trainer, DataCollatorForLanguageModeling\n)\nfrom peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\nfrom datasets import load_dataset\nimport torch\n\ndef setup_lora_training(model_name=\"mistralai/Mistral-7B-v0.1\"):\n    # Load model in 4-bit\n    model = AutoModelForCausalLM.from_pretrained(\n        model_name,\n        load_in_4bit=True,\n        torch_dtype=torch.float16,\n        device_map=\"auto\"\n    )\n    \n    tokenizer = AutoTokenizer.from_pretrained(model_name)\n    tokenizer.pad_token = tokenizer.eos_token\n    \n    # Prepare for training\n    model = prepare_model_for_kbit_training(model)\n    \n    # LoRA config\n    lora_config = LoraConfig(\n        r=16,  # Rank\n        lora_alpha=32,\n        target_modules=[\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\"],\n        lora_dropout=0.05,\n        bias=\"none\",\n        task_type=\"CAUSAL_LM\"\n    )\n    \n    model = get_peft_model(model, lora_config)\n    model.print_trainable_parameters()\n    \n    return model, tokenizer\n\ndef train_lora(model, tokenizer, dataset, output_dir=\"./lora-output\"):\n    training_args = TrainingArguments(\n        output_dir=output_dir,\n        num_train_epochs=3,\n        per_device_train_batch_size=4,\n        gradient_accumulation_steps=4,\n        learning_rate=2e-4,\n        logging_steps=10,\n        save_steps=100,\n        fp16=True,\n        warmup_ratio=0.1,\n    )\n    \n    trainer = Trainer(\n        model=model,\n        args=training_args,\n        train_dataset=dataset,\n        data_collator=DataCollatorForLanguageModeling(tokenizer, mlm=False)\n    )\n    \n    trainer.train()\n    model.save_pretrained(output_dir)\n    return model\n\n# Usage\nmodel, tokenizer = setup_lora_training()\n# Load and prepare your dataset\n# model = train_lora(model, tokenizer, dataset)\n```\n\n**Evaluation After Fine-tuning:**\n```python\ndef evaluate_finetuned(model_id, test_cases):\n    from openai import OpenAI\n    client = OpenAI()\n    \n    results = []\n    for test in test_cases:\n        response = client.chat.completions.create(\n            model=model_id,\n            messages=[{\"role\": \"user\", \"content\": test[\"input\"]}],\n            temperature=0\n        )\n        \n        result = {\n            \"input\": test[\"input\"],\n            \"expected\": test[\"expected\"],\n            \"actual\": response.choices[0].message.content,\n            \"match\": response.choices[0].message.content.strip() == test[\"expected\"].strip()\n        }\n        results.append(result)\n    \n    accuracy = sum(r[\"match\"] for r in results) / len(results)\n    print(f\"Accuracy: {accuracy:.2%}\")\n    return results\n```",
  "prompt": "A skill for fine-tuning language models",
  "createdAt": "2024-01-15T10:00:00.000Z",
  "published": true
}
