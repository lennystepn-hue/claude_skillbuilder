{
  "id": "backend-logging",
  "name": "Application Logging and Monitoring",
  "description": "Implement production-ready logging with Winston, structured logs, log levels, transports, and log aggregation systems",
  "category": "Backend",
  "content": "---\nname: Application Logging and Monitoring\ndescription: Implement production-ready logging with Winston, structured logs, log levels, transports, and log aggregation systems\ncategory: Backend\n---\n\n# Application Logging and Monitoring\n\n## Overview\n\nThis skill provides comprehensive patterns for implementing production-grade logging systems in backend applications. It covers structured logging, log levels, transports, rotation, aggregation, correlation IDs, performance monitoring, and integration with popular logging services.\n\n## Activation\n\nUse this skill when:\n- Setting up logging for a new application\n- Implementing structured logging\n- Configuring log rotation and archival\n- Integrating with log aggregation services (ELK, Datadog, Cloudwatch)\n- Adding request/response logging middleware\n- Implementing correlation IDs for request tracking\n- Setting up error tracking and alerting\n- User mentions \"logging\", \"winston\", \"pino\", \"log aggregation\", or \"monitoring\"\n\n## Instructions\n\n1. **Choose the Right Logging Library**\n   - Use Winston for flexibility and multiple transports\n   - Use Pino for high performance and low overhead\n   - Use Bunyan for JSON logging and CLI tools\n   - Consider Morgan for HTTP request logging\n\n2. **Implement Structured Logging**\n   - Always use JSON format for logs\n   - Include consistent metadata (timestamp, level, service name)\n   - Add correlation IDs to trace requests\n   - Include context-specific data\n\n3. **Use Appropriate Log Levels**\n   - ERROR: Errors that need immediate attention\n   - WARN: Warning conditions that should be investigated\n   - INFO: Important business process information\n   - DEBUG: Detailed debugging information\n   - TRACE: Very detailed diagnostic information\n\n4. **Configure Transports Properly**\n   - Console for development\n   - File with rotation for production\n   - External services (CloudWatch, Datadog, etc.) for monitoring\n   - Different transports for different log levels\n\n5. **Implement Log Rotation**\n   - Rotate logs by size or date\n   - Compress old logs\n   - Set retention policies\n   - Monitor disk usage\n\n6. **Security Considerations**\n   - Never log sensitive data (passwords, tokens, PII)\n   - Sanitize user input before logging\n   - Use log levels to control production verbosity\n   - Implement audit logging for security events\n\n7. **Performance Best Practices**\n   - Use async transports to avoid blocking\n   - Implement sampling for high-volume logs\n   - Use appropriate log levels\n   - Avoid logging in tight loops\n\n## Examples\n\n### Example 1: Winston Logger Setup\n\n```javascript\n// logger.js - Production-ready Winston configuration\nconst winston = require('winston');\nconst DailyRotateFile = require('winston-daily-rotate-file');\nconst path = require('path');\n\n// Custom format for pretty console output in development\nconst consoleFormat = winston.format.combine(\n  winston.format.colorize(),\n  winston.format.timestamp({ format: 'YYYY-MM-DD HH:mm:ss' }),\n  winston.format.printf(({ timestamp, level, message, ...meta }) => {\n    let msg = `${timestamp} [${level}]: ${message}`;\n    \n    // Add metadata if present\n    if (Object.keys(meta).length > 0) {\n      msg += ` ${JSON.stringify(meta)}`;\n    }\n    \n    return msg;\n  })\n);\n\n// JSON format for file and external services\nconst jsonFormat = winston.format.combine(\n  winston.format.timestamp(),\n  winston.format.errors({ stack: true }),\n  winston.format.json()\n);\n\n// Create transports\nconst transports = [];\n\n// Console transport for development\nif (process.env.NODE_ENV !== 'production') {\n  transports.push(\n    new winston.transports.Console({\n      format: consoleFormat,\n      level: 'debug'\n    })\n  );\n} else {\n  transports.push(\n    new winston.transports.Console({\n      format: jsonFormat,\n      level: 'info'\n    })\n  );\n}\n\n// File transport with rotation for errors\ntransports.push(\n  new DailyRotateFile({\n    filename: path.join('logs', 'error-%DATE%.log'),\n    datePattern: 'YYYY-MM-DD',\n    level: 'error',\n    format: jsonFormat,\n    maxSize: '20m',\n    maxFiles: '14d',\n    compress: true\n  })\n);\n\n// File transport with rotation for all logs\ntransports.push(\n  new DailyRotateFile({\n    filename: path.join('logs', 'combined-%DATE%.log'),\n    datePattern: 'YYYY-MM-DD',\n    format: jsonFormat,\n    maxSize: '20m',\n    maxFiles: '7d',\n    compress: true\n  })\n);\n\n// Create the logger\nconst logger = winston.createLogger({\n  level: process.env.LOG_LEVEL || 'info',\n  format: jsonFormat,\n  defaultMeta: {\n    service: process.env.SERVICE_NAME || 'api',\n    environment: process.env.NODE_ENV || 'development',\n    version: process.env.APP_VERSION || '1.0.0'\n  },\n  transports,\n  exitOnError: false\n});\n\n// Add CloudWatch transport in production\nif (process.env.NODE_ENV === 'production' && process.env.AWS_CLOUDWATCH_GROUP) {\n  const CloudWatchTransport = require('winston-cloudwatch');\n  \n  logger.add(\n    new CloudWatchTransport({\n      logGroupName: process.env.AWS_CLOUDWATCH_GROUP,\n      logStreamName: `${process.env.SERVICE_NAME}-${new Date().toISOString().split('T')[0]}`,\n      awsRegion: process.env.AWS_REGION,\n      jsonMessage: true,\n      level: 'info'\n    })\n  );\n}\n\n// Helper methods for common logging patterns\nlogger.logRequest = (req, res, duration) => {\n  logger.info('HTTP Request', {\n    method: req.method,\n    url: req.url,\n    statusCode: res.statusCode,\n    duration: `${duration}ms`,\n    ip: req.ip,\n    userAgent: req.get('user-agent'),\n    correlationId: req.correlationId\n  });\n};\n\nlogger.logError = (error, context = {}) => {\n  logger.error('Application Error', {\n    message: error.message,\n    stack: error.stack,\n    code: error.code,\n    ...context\n  });\n};\n\nlogger.logDatabaseQuery = (query, duration, result) => {\n  logger.debug('Database Query', {\n    query: query.sql || query,\n    duration: `${duration}ms`,\n    rowCount: result?.rowCount || result?.length,\n    type: query.constructor.name\n  });\n};\n\nlogger.logPerformance = (operation, duration, metadata = {}) => {\n  const level = duration > 1000 ? 'warn' : 'info';\n  logger.log(level, 'Performance Metric', {\n    operation,\n    duration: `${duration}ms`,\n    ...metadata\n  });\n};\n\nmodule.exports = logger;\n```\n\n### Example 2: Express Logging Middleware\n\n```javascript\n// middleware/logging.js - Comprehensive request/response logging\nconst logger = require('../logger');\nconst { v4: uuidv4 } = require('uuid');\nconst onFinished = require('on-finished');\n\n// Correlation ID middleware\nfunction correlationId(req, res, next) {\n  // Use existing correlation ID from header or generate new one\n  req.correlationId = req.headers['x-correlation-id'] || uuidv4();\n  \n  // Add to response headers\n  res.setHeader('X-Correlation-Id', req.correlationId);\n  \n  // Add to logger context\n  req.logger = logger.child({ correlationId: req.correlationId });\n  \n  next();\n}\n\n// Request logging middleware\nfunction requestLogger(req, res, next) {\n  const startTime = Date.now();\n  \n  // Log incoming request\n  req.logger.info('Incoming Request', {\n    method: req.method,\n    url: req.url,\n    query: req.query,\n    ip: req.ip,\n    userAgent: req.get('user-agent'),\n    referer: req.get('referer')\n  });\n  \n  // Log when response finishes\n  onFinished(res, (err, res) => {\n    const duration = Date.now() - startTime;\n    const logData = {\n      method: req.method,\n      url: req.url,\n      statusCode: res.statusCode,\n      duration: `${duration}ms`,\n      contentLength: res.get('content-length'),\n      ip: req.ip\n    };\n    \n    if (err) {\n      req.logger.error('Request Error', { ...logData, error: err.message });\n    } else if (res.statusCode >= 500) {\n      req.logger.error('Server Error Response', logData);\n    } else if (res.statusCode >= 400) {\n      req.logger.warn('Client Error Response', logData);\n    } else {\n      req.logger.info('Request Completed', logData);\n    }\n  });\n  \n  next();\n}\n\n// Error logging middleware\nfunction errorLogger(err, req, res, next) {\n  const errorData = {\n    message: err.message,\n    stack: err.stack,\n    code: err.code,\n    statusCode: err.statusCode || 500,\n    method: req.method,\n    url: req.url,\n    correlationId: req.correlationId,\n    userId: req.user?.id,\n    body: sanitizeBody(req.body)\n  };\n  \n  // Log based on error severity\n  if (err.statusCode && err.statusCode < 500) {\n    req.logger.warn('Client Error', errorData);\n  } else {\n    req.logger.error('Server Error', errorData);\n  }\n  \n  next(err);\n}\n\n// Sanitize request body to remove sensitive data\nfunction sanitizeBody(body) {\n  if (!body) return body;\n  \n  const sensitiveFields = ['password', 'token', 'secret', 'apiKey', 'creditCard'];\n  const sanitized = { ...body };\n  \n  for (const field of sensitiveFields) {\n    if (sanitized[field]) {\n      sanitized[field] = '[REDACTED]';\n    }\n  }\n  \n  return sanitized;\n}\n\n// Slow query logger middleware\nfunction slowQueryLogger(threshold = 1000) {\n  return (req, res, next) => {\n    const startTime = Date.now();\n    \n    onFinished(res, () => {\n      const duration = Date.now() - startTime;\n      \n      if (duration > threshold) {\n        req.logger.warn('Slow Request Detected', {\n          method: req.method,\n          url: req.url,\n          duration: `${duration}ms`,\n          threshold: `${threshold}ms`,\n          statusCode: res.statusCode\n        });\n      }\n    });\n    \n    next();\n  };\n}\n\nmodule.exports = {\n  correlationId,\n  requestLogger,\n  errorLogger,\n  slowQueryLogger\n};\n```\n\n### Example 3: Database Query Logging\n\n```javascript\n// database/logger.js - Database query logging with performance tracking\nconst logger = require('../logger');\n\n// Sequelize query logger\nfunction sequelizeLogger(queryLogger = logger) {\n  return (query, options) => {\n    const startTime = Date.now();\n    const type = options?.type || 'UNKNOWN';\n    const bind = options?.bind || [];\n    \n    // Log query start in debug mode\n    queryLogger.debug('Database Query Started', {\n      type,\n      query: query.substring(0, 500), // Truncate long queries\n      bind: bind.length > 0 ? bind : undefined\n    });\n    \n    // Return a function to log completion\n    return () => {\n      const duration = Date.now() - startTime;\n      const level = duration > 1000 ? 'warn' : 'debug';\n      \n      queryLogger.log(level, 'Database Query Completed', {\n        type,\n        duration: `${duration}ms`,\n        query: query.substring(0, 200)\n      });\n    };\n  };\n}\n\n// MongoDB query logger\nclass MongoLogger {\n  constructor(mongoose, logger) {\n    this.logger = logger;\n    \n    // Enable query logging\n    mongoose.set('debug', (collection, method, query, doc, options) => {\n      this.logger.debug('MongoDB Query', {\n        collection,\n        method,\n        query: JSON.stringify(query),\n        doc: doc ? JSON.stringify(doc).substring(0, 200) : undefined,\n        options: options ? JSON.stringify(options) : undefined\n      });\n    });\n  }\n  \n  // Middleware for query performance tracking\n  performanceMiddleware() {\n    return function(schema) {\n      const logger = this.logger;\n      \n      // Pre-query hook\n      schema.pre(/^find/, function() {\n        this._startTime = Date.now();\n      });\n      \n      // Post-query hook\n      schema.post(/^find/, function(result) {\n        const duration = Date.now() - this._startTime;\n        const level = duration > 500 ? 'warn' : 'debug';\n        \n        logger.log(level, 'MongoDB Query Performance', {\n          operation: this.op,\n          collection: this.mongooseCollection.name,\n          duration: `${duration}ms`,\n          resultCount: Array.isArray(result) ? result.length : 1,\n          conditions: JSON.stringify(this.getFilter())\n        });\n      });\n    };\n  }\n}\n\n// Prisma query logger\nfunction createPrismaLogger(logger) {\n  return {\n    query: (e) => {\n      logger.debug('Prisma Query', {\n        query: e.query,\n        params: e.params,\n        duration: `${e.duration}ms`,\n        target: e.target\n      });\n    },\n    \n    info: (e) => {\n      logger.info('Prisma Info', { message: e.message });\n    },\n    \n    warn: (e) => {\n      logger.warn('Prisma Warning', { message: e.message });\n    },\n    \n    error: (e) => {\n      logger.error('Prisma Error', { message: e.message });\n    }\n  };\n}\n\n// Query performance decorator\nfunction logQuery(target, propertyKey, descriptor) {\n  const originalMethod = descriptor.value;\n  \n  descriptor.value = async function(...args) {\n    const startTime = Date.now();\n    const methodName = `${target.constructor.name}.${propertyKey}`;\n    \n    logger.debug('Query Method Started', {\n      method: methodName,\n      args: JSON.stringify(args).substring(0, 200)\n    });\n    \n    try {\n      const result = await originalMethod.apply(this, args);\n      const duration = Date.now() - startTime;\n      \n      logger.info('Query Method Completed', {\n        method: methodName,\n        duration: `${duration}ms`,\n        resultCount: Array.isArray(result) ? result.length : 1\n      });\n      \n      return result;\n    } catch (error) {\n      const duration = Date.now() - startTime;\n      \n      logger.error('Query Method Failed', {\n        method: methodName,\n        duration: `${duration}ms`,\n        error: error.message,\n        stack: error.stack\n      });\n      \n      throw error;\n    }\n  };\n  \n  return descriptor;\n}\n\nmodule.exports = {\n  sequelizeLogger,\n  MongoLogger,\n  createPrismaLogger,\n  logQuery\n};\n```\n\n### Example 4: Structured Application Logging\n\n```javascript\n// services/user-service.js - Service with comprehensive logging\nconst logger = require('../logger');\nconst { logQuery } = require('../database/logger');\n\nclass UserService {\n  constructor(userRepository) {\n    this.userRepository = userRepository;\n    this.logger = logger.child({ service: 'UserService' });\n  }\n  \n  async createUser(userData) {\n    const operationId = generateOperationId();\n    const contextLogger = this.logger.child({ operationId, operation: 'createUser' });\n    \n    contextLogger.info('Creating new user', {\n      email: userData.email,\n      role: userData.role\n    });\n    \n    try {\n      // Validate user data\n      const validation = this.validateUserData(userData);\n      if (!validation.valid) {\n        contextLogger.warn('User validation failed', {\n          errors: validation.errors\n        });\n        throw new ValidationError('Invalid user data', validation.errors);\n      }\n      \n      // Check if user exists\n      const existingUser = await this.userRepository.findByEmail(userData.email);\n      if (existingUser) {\n        contextLogger.warn('User already exists', {\n          email: userData.email\n        });\n        throw new ConflictError('User already exists');\n      }\n      \n      // Create user\n      const startTime = Date.now();\n      const user = await this.userRepository.create(userData);\n      const duration = Date.now() - startTime;\n      \n      contextLogger.info('User created successfully', {\n        userId: user.id,\n        email: user.email,\n        duration: `${duration}ms`\n      });\n      \n      // Log business event\n      this.logBusinessEvent('user.created', {\n        userId: user.id,\n        email: user.email,\n        role: user.role,\n        source: userData.source || 'api'\n      });\n      \n      return user;\n      \n    } catch (error) {\n      contextLogger.error('Failed to create user', {\n        error: error.message,\n        stack: error.stack,\n        email: userData.email\n      });\n      \n      throw error;\n    }\n  }\n  \n  async deleteUser(userId, deletedBy) {\n    const contextLogger = this.logger.child({\n      operation: 'deleteUser',\n      userId,\n      deletedBy\n    });\n    \n    contextLogger.info('Deleting user');\n    \n    try {\n      const user = await this.userRepository.findById(userId);\n      \n      if (!user) {\n        contextLogger.warn('User not found');\n        throw new NotFoundError('User not found');\n      }\n      \n      await this.userRepository.delete(userId);\n      \n      contextLogger.info('User deleted successfully');\n      \n      // Log audit event\n      this.logAuditEvent('user.deleted', {\n        userId,\n        userEmail: user.email,\n        deletedBy,\n        timestamp: new Date()\n      });\n      \n    } catch (error) {\n      contextLogger.error('Failed to delete user', {\n        error: error.message,\n        stack: error.stack\n      });\n      \n      throw error;\n    }\n  }\n  \n  logBusinessEvent(eventType, data) {\n    logger.info('Business Event', {\n      eventType,\n      eventData: data,\n      timestamp: new Date(),\n      category: 'business'\n    });\n  }\n  \n  logAuditEvent(eventType, data) {\n    logger.info('Audit Event', {\n      eventType,\n      eventData: data,\n      timestamp: new Date(),\n      category: 'audit'\n    });\n  }\n  \n  validateUserData(userData) {\n    // Validation logic\n    return { valid: true, errors: [] };\n  }\n}\n\nfunction generateOperationId() {\n  return Date.now().toString(36) + Math.random().toString(36).substr(2);\n}\n\nmodule.exports = UserService;\n```\n\n### Example 5: Centralized Log Aggregation Setup\n\n```javascript\n// logger/aggregation.js - Integration with log aggregation services\nconst winston = require('winston');\nconst { ElasticsearchTransport } = require('winston-elasticsearch');\nconst DatadogWinston = require('datadog-winston');\nconst { LoggingWinston } = require('@google-cloud/logging-winston');\n\n// Elasticsearch configuration\nfunction createElasticsearchTransport() {\n  return new ElasticsearchTransport({\n    level: 'info',\n    clientOpts: {\n      node: process.env.ELASTICSEARCH_URL,\n      auth: {\n        username: process.env.ELASTICSEARCH_USER,\n        password: process.env.ELASTICSEARCH_PASSWORD\n      },\n      ssl: {\n        rejectUnauthorized: process.env.NODE_ENV === 'production'\n      }\n    },\n    index: `logs-${process.env.SERVICE_NAME}`,\n    transformer: (logData) => {\n      return {\n        '@timestamp': logData.timestamp,\n        message: logData.message,\n        severity: logData.level,\n        fields: {\n          ...logData.meta,\n          service: process.env.SERVICE_NAME,\n          environment: process.env.NODE_ENV\n        }\n      };\n    }\n  });\n}\n\n// Datadog configuration\nfunction createDatadogTransport() {\n  return new DatadogWinston({\n    apiKey: process.env.DATADOG_API_KEY,\n    hostname: process.env.HOSTNAME || 'localhost',\n    service: process.env.SERVICE_NAME,\n    ddsource: 'nodejs',\n    ddtags: `env:${process.env.NODE_ENV},version:${process.env.APP_VERSION}`\n  });\n}\n\n// Google Cloud Logging configuration\nfunction createGoogleCloudTransport() {\n  return new LoggingWinston({\n    projectId: process.env.GCP_PROJECT_ID,\n    keyFilename: process.env.GCP_KEY_FILE,\n    logName: process.env.SERVICE_NAME,\n    resource: {\n      type: 'generic_node',\n      labels: {\n        project_id: process.env.GCP_PROJECT_ID,\n        location: process.env.GCP_REGION,\n        namespace: process.env.SERVICE_NAME\n      }\n    }\n  });\n}\n\n// Create logger with multiple aggregation services\nfunction createAggregatedLogger() {\n  const transports = [\n    new winston.transports.Console({\n      format: winston.format.combine(\n        winston.format.colorize(),\n        winston.format.simple()\n      )\n    })\n  ];\n  \n  // Add Elasticsearch in production\n  if (process.env.ELASTICSEARCH_URL) {\n    transports.push(createElasticsearchTransport());\n  }\n  \n  // Add Datadog if configured\n  if (process.env.DATADOG_API_KEY) {\n    transports.push(createDatadogTransport());\n  }\n  \n  // Add Google Cloud Logging if configured\n  if (process.env.GCP_PROJECT_ID) {\n    transports.push(createGoogleCloudTransport());\n  }\n  \n  return winston.createLogger({\n    level: process.env.LOG_LEVEL || 'info',\n    format: winston.format.combine(\n      winston.format.timestamp(),\n      winston.format.errors({ stack: true }),\n      winston.format.json()\n    ),\n    defaultMeta: {\n      service: process.env.SERVICE_NAME,\n      environment: process.env.NODE_ENV,\n      version: process.env.APP_VERSION,\n      hostname: process.env.HOSTNAME\n    },\n    transports\n  });\n}\n\n// Metric logging for monitoring\nclass MetricsLogger {\n  constructor(logger) {\n    this.logger = logger;\n    this.metrics = new Map();\n  }\n  \n  increment(metric, value = 1, tags = {}) {\n    this.logger.info('Metric Increment', {\n      metric,\n      value,\n      tags,\n      type: 'counter'\n    });\n  }\n  \n  gauge(metric, value, tags = {}) {\n    this.logger.info('Metric Gauge', {\n      metric,\n      value,\n      tags,\n      type: 'gauge'\n    });\n  }\n  \n  histogram(metric, value, tags = {}) {\n    this.logger.info('Metric Histogram', {\n      metric,\n      value,\n      tags,\n      type: 'histogram'\n    });\n  }\n  \n  timing(metric, duration, tags = {}) {\n    this.logger.info('Metric Timing', {\n      metric,\n      duration: `${duration}ms`,\n      tags,\n      type: 'timing'\n    });\n  }\n}\n\nmodule.exports = {\n  createAggregatedLogger,\n  createElasticsearchTransport,\n  createDatadogTransport,\n  createGoogleCloudTransport,\n  MetricsLogger\n};\n```",
  "prompt": "A skill that implements production-ready application logging using Winston, structured logging, log levels, multiple transports, log rotation, correlation IDs, database query logging, and integration with log aggregation services like Elasticsearch, Datadog, and Google Cloud Logging.",
  "createdAt": "2024-01-15T10:00:00.000Z",
  "published": true
}
